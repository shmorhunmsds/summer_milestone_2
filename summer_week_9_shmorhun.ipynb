{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e53aadef",
   "metadata": {},
   "source": [
    "### 9.2 Activity: Jupyter Notebook â€“ Gradient Boost\n",
    "\n",
    "For this week, include ideas such as gradient boost, learning rate, number of estimators, tree depth, and regularization. This homework should be submitted for peer review in the assignment titled 9.3 Peer Review: Week 9 Jupyter Notebook. Complete and submit your Jupyter Notebook homework by 11:59pm ET on Sunday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788118f8",
   "metadata": {},
   "source": [
    "Ok the plan:\n",
    "- Try a vanilla GBM on all 3 datasets, with some tuning\n",
    "- Go ahead and drop in XGBoost Classifier and XGBoost Regressor and try some model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5c22f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 5090 (UUID: GPU-f7f57dfb-5480-a1d6-1870-ac9f5f47ce36)\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab22345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aa9d85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original holdout distribution:\n",
      "Holdout set: concussed\n",
      "0    54544\n",
      "1        6\n",
      "Name: count, dtype: int64\n",
      "Training set: concussed\n",
      "0    218172\n",
      "1        26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X= pd.read_csv('scripts/punt_analytics/motion_features_X_full.csv')\n",
    "y = pd.read_csv('scripts/punt_analytics/motion_labels_y_full.csv')['concussed']\n",
    "\n",
    "# First, split the ORIGINAL data before any resampling\n",
    "X_original_train, X_holdout, y_original_train, y_holdout = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Original holdout distribution:\")\n",
    "print(f\"Holdout set: {pd.Series(y_holdout).value_counts()}\")\n",
    "print(f\"Training set: {pd.Series(y_original_train).value_counts()}\")\n",
    "\n",
    "# Resample only the training data\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.01)\n",
    "oversample = SMOTE(sampling_strategy=0.1)\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    ('undersample', undersample),\n",
    "    ('oversample', oversample)\n",
    "])\n",
    "\n",
    "X_resampled, y_resampled = pipeline.fit_resample(X_original_train, y_original_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c82a56b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2860, 240), (54550, 240), (2860,), (54550,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape, X_holdout.shape, y_resampled.shape, y_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128a29aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag/lead features...\n",
      "Creating statistical features...\n",
      "Creating interaction features...\n",
      "Defragmenting dataframe...\n",
      "Final shape: (2860, 520)\n",
      "Creating lag/lead features...\n",
      "Creating statistical features...\n",
      "Creating interaction features...\n",
      "Defragmenting dataframe...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48939/28632552.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  stds / np.abs(means),\n",
      "/tmp/ipykernel_48939/28632552.py:128: RuntimeWarning: divide by zero encountered in divide\n",
      "  new_features['total_displacement'] / total_distance,\n",
      "/tmp/ipykernel_48939/28632552.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  new_features['total_displacement'] / total_distance,\n",
      "/tmp/ipykernel_48939/28632552.py:75: RuntimeWarning: invalid value encountered in divide\n",
      "  stds / np.abs(means),\n",
      "/tmp/ipykernel_48939/28632552.py:128: RuntimeWarning: divide by zero encountered in divide\n",
      "  new_features['total_displacement'] / total_distance,\n",
      "/tmp/ipykernel_48939/28632552.py:128: RuntimeWarning: invalid value encountered in divide\n",
      "  new_features['total_displacement'] / total_distance,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (54550, 520)\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features_optimized(df):\n",
    "    \"\"\"Optimized lag feature creation - builds all features at once\"\"\"\n",
    "    variables = ['dis', 'o',  'x', 'y']\n",
    "    \n",
    "    # Collect all new columns in a list first\n",
    "    new_columns = {}\n",
    "    \n",
    "    for var in variables:\n",
    "        cols = [f'{var}_slice_{i}' for i in range(10)]\n",
    "        \n",
    "        # Create lag features (previous time steps)\n",
    "        for lag in [1, 2, 3]:\n",
    "            for i in range(lag, 10):\n",
    "                col_name = f'{var}_slice_{i}_lag{lag}'\n",
    "                new_columns[col_name] = df[f'{var}_slice_{i-lag}'].values\n",
    "        \n",
    "        # Create lead features (future time steps)  \n",
    "        for lead in [1, 2]:\n",
    "            for i in range(10-lead):\n",
    "                col_name = f'{var}_slice_{i}_lead{lead}'\n",
    "                new_columns[col_name] = df[f'{var}_slice_{i+lead}'].values\n",
    "    \n",
    "    # Create new dataframe with all lag/lead features at once\n",
    "    new_features_df = pd.DataFrame(new_columns, index=df.index)\n",
    "    \n",
    "    # Concatenate with original dataframe\n",
    "    result_df = pd.concat([df, new_features_df], axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_time_series_features_optimized(df):\n",
    "    \"\"\"Optimized statistical time series feature creation\"\"\"\n",
    "    variables = ['dis', 'o', 'x', 'y']\n",
    "\n",
    "    # Collect all new features\n",
    "    new_features = {}\n",
    "    \n",
    "    for var in variables:\n",
    "        cols = [f'{var}_slice_{i}' for i in range(10)]\n",
    "        \n",
    "        # Get the data matrix for this variable (all time slices)\n",
    "        data_matrix = df[cols].values\n",
    "        \n",
    "        # Compute all statistical features vectorized\n",
    "        new_features[f'{var}_trend'] = np.nanmean(np.diff(data_matrix, axis=1), axis=1)\n",
    "        new_features[f'{var}_slope'] = (data_matrix[:, -1] - data_matrix[:, 0]) / 9\n",
    "        new_features[f'{var}_mean'] = np.nanmean(data_matrix, axis=1)\n",
    "        new_features[f'{var}_std'] = np.nanstd(data_matrix, axis=1)\n",
    "        new_features[f'{var}_min'] = np.nanmin(data_matrix, axis=1)\n",
    "        new_features[f'{var}_max'] = np.nanmax(data_matrix, axis=1)\n",
    "        new_features[f'{var}_range'] = new_features[f'{var}_max'] - new_features[f'{var}_min']\n",
    "        \n",
    "        # Change point features\n",
    "        new_features[f'{var}_early_mean'] = np.nanmean(data_matrix[:, :3], axis=1)\n",
    "        new_features[f'{var}_late_mean'] = np.nanmean(data_matrix[:, 7:], axis=1)\n",
    "        new_features[f'{var}_early_late_diff'] = new_features[f'{var}_late_mean'] - new_features[f'{var}_early_mean']\n",
    "        \n",
    "        # Volatility features\n",
    "        new_features[f'{var}_volatility'] = np.nanstd(np.diff(data_matrix, axis=1), axis=1)\n",
    "        \n",
    "        # Pattern recognition features\n",
    "        diff_matrix = np.diff(data_matrix, axis=1)\n",
    "        new_features[f'{var}_monotonic_increase'] = np.sum(diff_matrix > 0, axis=1)\n",
    "        new_features[f'{var}_monotonic_decrease'] = np.sum(diff_matrix < 0, axis=1)\n",
    "        \n",
    "        # Direction changes (second derivative)\n",
    "        second_diff = np.diff(diff_matrix, axis=1)\n",
    "        new_features[f'{var}_direction_changes'] = np.sum(second_diff != 0, axis=1)\n",
    "        \n",
    "        # Coefficient of variation (handle division by zero)\n",
    "        means = new_features[f'{var}_mean']\n",
    "        stds = new_features[f'{var}_std']\n",
    "        new_features[f'{var}_coefficient_variation'] = np.where(\n",
    "            np.abs(means) > 1e-8, \n",
    "            stds / np.abs(means), \n",
    "            0\n",
    "        )\n",
    "        \n",
    "        # Time-weighted features (recent values matter more)\n",
    "        weights = np.arange(1, 11)  # 1, 2, 3, ..., 10\n",
    "        weighted_sum = np.sum(data_matrix * weights, axis=1)\n",
    "        new_features[f'{var}_weighted_mean'] = weighted_sum / np.sum(weights)\n",
    "    \n",
    "    # Create dataframe from all new features\n",
    "    new_features_df = pd.DataFrame(new_features, index=df.index)\n",
    "    \n",
    "    # Concatenate with original\n",
    "    result_df = pd.concat([df, new_features_df], axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_interaction_features_optimized(df):\n",
    "    \"\"\"Optimized interaction feature creation\"\"\"\n",
    "    new_features = {}\n",
    "    \n",
    "    # Cross-variable interactions at each time slice\n",
    "    for i in range(10):\n",
    "        new_features[f'x_y_interaction_{i}'] = df[f'x_slice_{i}'] * df[f'y_slice_{i}']\n",
    "        new_features[f'dis_o_interaction_{i}'] = df[f'dis_slice_{i}'] * df[f'o_slice_{i}']\n",
    "        \n",
    "        # Distance-like features\n",
    "        new_features[f'euclidean_distance_{i}'] = np.sqrt(\n",
    "            df[f'x_slice_{i}']**2 + df[f'y_slice_{i}']**2\n",
    "        )\n",
    "        \n",
    "        # Angle-like features (if o represents orientation)\n",
    "        new_features[f'velocity_x_{i}'] = df[f'dis_slice_{i}'] * np.cos(df[f'o_slice_{i}'])\n",
    "        new_features[f'velocity_y_{i}'] = df[f'dis_slice_{i}'] * np.sin(df[f'o_slice_{i}'])\n",
    "    \n",
    "    # Multi-variable aggregate features\n",
    "    x_cols = [f'x_slice_{i}' for i in range(10)]\n",
    "    y_cols = [f'y_slice_{i}' for i in range(10)]\n",
    "    dis_cols = [f'dis_slice_{i}' for i in range(10)]\n",
    "    \n",
    "    # Total displacement path\n",
    "    x_data = df[x_cols].values\n",
    "    y_data = df[y_cols].values\n",
    "    \n",
    "    new_features['total_displacement'] = np.sqrt(\n",
    "        (x_data[:, -1] - x_data[:, 0])**2 + \n",
    "        (y_data[:, -1] - y_data[:, 0])**2\n",
    "    )\n",
    "    \n",
    "    # Path efficiency (straight line vs actual path)\n",
    "    total_distance = np.sum(df[dis_cols].values, axis=1)\n",
    "    new_features['path_efficiency'] = np.where(\n",
    "        total_distance > 1e-8,\n",
    "        new_features['total_displacement'] / total_distance,\n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Create dataframe and concatenate\n",
    "    new_features_df = pd.DataFrame(new_features, index=df.index)\n",
    "    result_df = pd.concat([df, new_features_df], axis=1)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def create_all_time_series_features(df):\n",
    "    \"\"\"Create all time series features efficiently\"\"\"\n",
    "    print(\"Creating lag/lead features...\")\n",
    "    df = create_lag_features_optimized(df)\n",
    "    \n",
    "    print(\"Creating statistical features...\")\n",
    "    df = create_time_series_features_optimized(df)\n",
    "    \n",
    "    print(\"Creating interaction features...\")\n",
    "    df = create_interaction_features_optimized(df)\n",
    "    \n",
    "    # Defragment the dataframe\n",
    "    print(\"Defragmenting dataframe...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(f\"Final shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "# Usage:\n",
    "# df_enhanced = create_all_time_series_features(df)\n",
    "# \n",
    "# This will be much faster and won't generate performance warnings!\n",
    "\n",
    "X_train = create_all_time_series_features(X_resampled)\n",
    "X_holdout = create_all_time_series_features(X_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6cf919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "concussed",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "37aa6598-11e7-40d9-9f2a-70c804e5c05a",
       "rows": [
        [
         "0",
         "2600"
        ],
        [
         "1",
         "260"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "concussed\n",
       "0    2600\n",
       "1     260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c3d98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix as conf_matrix, roc_auc_score, log_loss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def diagnose_and_train_xgboost_classifier(X, y, use_time_split=False, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Comprehensive XGBoost CLASSIFICATION training with diagnostics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame - Features\n",
    "    y : Series/array - Target variable (class labels)\n",
    "    use_time_split : bool - Whether to use TimeSeriesSplit (only if rows are temporally ordered)\n",
    "    test_size : float - Test set proportion\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== DATA DIAGNOSTICS ===\")\n",
    "    print(f\"Features shape: {X.shape}\")\n",
    "    print(f\"Target shape: {y.shape}\")\n",
    "    print(f\"Target classes and counts:\")\n",
    "    print(pd.Series(y).value_counts().sort_index())\n",
    "    print(f\"Class balance:\")\n",
    "    for class_val in sorted(pd.Series(y).unique()):\n",
    "        prop = (pd.Series(y) == class_val).mean()\n",
    "        print(f\"  Class {class_val}: {prop:.3f} ({prop*100:.1f}%)\")\n",
    "    \n",
    "    # Determine if binary or multiclass\n",
    "    n_classes = len(pd.Series(y).unique())\n",
    "    is_binary = n_classes == 2\n",
    "    print(f\"Number of classes: {n_classes}\")\n",
    "    print(f\"Problem type: {'Binary' if is_binary else 'Multiclass'} Classification\")\n",
    "    \n",
    "    # Split data\n",
    "    if use_time_split:\n",
    "        print(\"\\n=== CHECKING TIME SERIES SPLIT FEASIBILITY ===\")\n",
    "        # Check if temporal split will have positive cases in test set\n",
    "        split_point = int(len(X) * (1 - test_size))\n",
    "        y_test_temp = y.iloc[split_point:]\n",
    "        positive_in_test = y_test_temp.sum()\n",
    "        \n",
    "        print(f\"Temporal split would put {positive_in_test} positive cases in test set\")\n",
    "        \n",
    "        if positive_in_test < 5:  # Minimum threshold for meaningful evaluation\n",
    "            print(f\"WARNING: Only {positive_in_test} positive cases in temporal test set!\")\n",
    "            print(\"Falling back to stratified random split to ensure proper evaluation...\")\n",
    "            \n",
    "            # Fall back to stratified split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=42, stratify=y\n",
    "            )\n",
    "            cv_method = 5  # Regular 5-fold CV\n",
    "            print(\"=== USING STRATIFIED RANDOM SPLIT (fallback) ===\")\n",
    "        else:\n",
    "            print(\"=== USING TIME SERIES SPLIT ===\")\n",
    "            # For actual time series data where row order matters\n",
    "            X_train, X_test = X.iloc[:split_point], X.iloc[split_point:]\n",
    "            y_train, y_test = y.iloc[:split_point], y.iloc[split_point:]\n",
    "            cv_method = TimeSeriesSplit(n_splits=5)\n",
    "    else:\n",
    "        print(\"\\n=== USING RANDOM SPLIT ===\")\n",
    "        # For independent sequences (more likely for your data)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=42, stratify=y\n",
    "        )\n",
    "        cv_method = 5  # Regular 5-fold CV\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "    print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "    \n",
    "    # XGBoost parameters for classification\n",
    "    if is_binary:\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 500,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'random_state': 42,\n",
    "            'device': 'cuda',      # GPU acceleration\n",
    "            'tree_method': 'hist', # Required for GPU\n",
    "            'n_jobs': 1           # Use 1 job when using GPU\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "    else:\n",
    "        params = {\n",
    "            'objective': 'multi:softprob',\n",
    "            'eval_metric': 'mlogloss',\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 500,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_alpha': 0.1,\n",
    "            'reg_lambda': 0.1,\n",
    "            'random_state': 42,\n",
    "            'device': 'cuda',      # GPU acceleration\n",
    "            'tree_method': 'hist', # Required for GPU\n",
    "            'n_jobs': 1           # Use 1 job when using GPU\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**params)\n",
    "    \n",
    "    print(\"\\n=== MODEL TRAINING ===\")\n",
    "    \n",
    "    # Cross-validation with appropriate scoring\n",
    "    scoring_metric = 'roc_auc' if is_binary else 'accuracy'\n",
    "    \n",
    "    if use_time_split:\n",
    "        cv_scores = []\n",
    "        for train_idx, val_idx in cv_method.split(X_train):\n",
    "            X_cv_train, X_cv_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_cv_train, y_cv_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            temp_model = xgb.XGBClassifier(**params)\n",
    "            temp_model.fit(X_cv_train, y_cv_train, verbose=False)\n",
    "            \n",
    "            if is_binary:\n",
    "                y_pred_proba = temp_model.predict_proba(X_cv_val)[:, 1]\n",
    "                score = roc_auc_score(y_cv_val, y_pred_proba)\n",
    "            else:\n",
    "                score = temp_model.score(X_cv_val, y_cv_val)\n",
    "            cv_scores.append(score)\n",
    "    else:\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv_method, scoring=scoring_metric)\n",
    "    \n",
    "    print(f\"Cross-validation {scoring_metric} scores: {cv_scores}\")\n",
    "    print(f\"Mean CV {scoring_metric}: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores) * 2:.4f})\")\n",
    "    \n",
    "    # Train final model\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    if is_binary:\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred_proba_train = model.predict_proba(X_train)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)\n",
    "    \n",
    "    print(\"\\n=== EVALUATION METRICS ===\")\n",
    "    print(\"Training Set:\")\n",
    "    print(f\"  Accuracy: {accuracy_score(y_train, y_pred_train):.4f}\")\n",
    "    if is_binary:\n",
    "        print(f\"  AUC-ROC: {roc_auc_score(y_train, y_pred_proba_train):.4f}\")\n",
    "        print(f\"  Log Loss: {log_loss(y_train, y_pred_proba_train):.4f}\")\n",
    "    else:\n",
    "        print(f\"  Log Loss: {log_loss(y_train, y_pred_proba_train):.4f}\")\n",
    "    \n",
    "    print(\"\\nTest Set:\")\n",
    "    print(f\"  Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
    "    if is_binary:\n",
    "        print(f\"  AUC-ROC: {roc_auc_score(y_test, y_pred_proba_test):.4f}\")\n",
    "        print(f\"  Log Loss: {log_loss(y_test, y_pred_proba_test):.4f}\")\n",
    "    else:\n",
    "        print(f\"  Log Loss: {log_loss(y_test, y_pred_proba_test):.4f}\")\n",
    "    \n",
    "    print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    print(\"\\n=== CONFUSION MATRIX ===\")\n",
    "    cm = conf_matrix(y_test, y_pred_test)\n",
    "    print(cm)\n",
    "    \n",
    "    # Feature importance\n",
    "    print(\"\\n=== TOP 10 FEATURE IMPORTANCES ===\")\n",
    "    \n",
    "    # Handle both DataFrame and NumPy array inputs\n",
    "    if hasattr(X, 'columns'):\n",
    "        feature_names = X.columns\n",
    "    else:\n",
    "        feature_names = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    # Baseline comparison\n",
    "    majority_class = pd.Series(y_train).mode()[0]\n",
    "    baseline_accuracy = (pd.Series(y_test) == majority_class).mean()\n",
    "    \n",
    "    print(f\"\\n=== BASELINE COMPARISON ===\")\n",
    "    print(f\"Baseline accuracy (majority class): {baseline_accuracy:.4f}\")\n",
    "    print(f\"Model improvement over baseline: {accuracy_score(y_test, y_pred_test) - baseline_accuracy:.4f}\")\n",
    "    \n",
    "    return model, {\n",
    "        'cv_scores': cv_scores,\n",
    "        'test_accuracy': accuracy_score(y_test, y_pred_test),\n",
    "        'test_auc': roc_auc_score(y_test, y_pred_proba_test) if is_binary else None,\n",
    "        'test_logloss': log_loss(y_test, y_pred_proba_test),\n",
    "        'feature_importance': feature_importance,\n",
    "        'classification_report': classification_report(y_test, y_pred_test, output_dict=True),\n",
    "        'confusion_matrix': conf_matrix(y_test, y_pred_test),\n",
    "        'y_pred_test': y_pred_test,\n",
    "        'y_pred_proba_test': y_pred_proba_test,\n",
    "        'y_test': y_test\n",
    "    }\n",
    "\n",
    "# Alternative: Simple baseline models for comparison\n",
    "def test_baseline_classifiers(X, y):\n",
    "    \"\"\"Test simple baseline classification models\"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.dummy import DummyClassifier\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'Majority Class': DummyClassifier(strategy='most_frequent'),\n",
    "        'Stratified': DummyClassifier(strategy='stratified', random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        results[name] = accuracy\n",
    "        print(f\"{name}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage examples:\n",
    "# model, results = diagnose_and_train_xgboost_classifier(X, y, use_time_split=False)\n",
    "# baseline_results = test_baseline_classifiers(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3df1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA DIAGNOSTICS ===\n",
      "Features shape: (2860, 520)\n",
      "Target shape: (2860,)\n",
      "Target classes and counts:\n",
      "concussed\n",
      "0    2600\n",
      "1     260\n",
      "Name: count, dtype: int64\n",
      "Class balance:\n",
      "  Class 0: 0.909 (90.9%)\n",
      "  Class 1: 0.091 (9.1%)\n",
      "Number of classes: 2\n",
      "Problem type: Binary Classification\n",
      "\n",
      "=== USING RANDOM SPLIT ===\n",
      "Training set: 2288 samples\n",
      "Test set: 572 samples\n",
      "\n",
      "=== MODEL TRAINING ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pshmo/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [23:04:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1738899731441/work/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation roc_auc scores: [0.99730998 0.9981685  0.98511905 0.99953096 0.99894465]\n",
      "Mean CV roc_auc: 0.9958 (+/- 0.0108)\n",
      "\n",
      "=== EVALUATION METRICS ===\n",
      "Training Set:\n",
      "  Accuracy: 1.0000\n",
      "  AUC-ROC: 1.0000\n",
      "  Log Loss: 0.0016\n",
      "\n",
      "Test Set:\n",
      "  Accuracy: 0.9930\n",
      "  AUC-ROC: 0.9977\n",
      "  Log Loss: 0.0239\n",
      "\n",
      "=== CLASSIFICATION REPORT ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       520\n",
      "           1       0.96      0.96      0.96        52\n",
      "\n",
      "    accuracy                           0.99       572\n",
      "   macro avg       0.98      0.98      0.98       572\n",
      "weighted avg       0.99      0.99      0.99       572\n",
      "\n",
      "\n",
      "=== CONFUSION MATRIX ===\n",
      "[[518   2]\n",
      " [  2  50]]\n",
      "\n",
      "=== TOP 10 FEATURE IMPORTANCES ===\n",
      "                   feature  importance\n",
      "327         x_slice_6_lag1    0.048116\n",
      "183              o_slice_3    0.028349\n",
      "422                 o_mean    0.024464\n",
      "354        x_slice_8_lead1    0.023177\n",
      "207             o_slice_27    0.022909\n",
      "250       dis_slice_3_lag2    0.022759\n",
      "326         x_slice_5_lag1    0.021977\n",
      "417  dis_direction_changes    0.021877\n",
      "331         x_slice_2_lag2    0.018456\n",
      "465    y_direction_changes    0.016286\n",
      "\n",
      "=== BASELINE COMPARISON ===\n",
      "Baseline accuracy (majority class): 0.9091\n",
      "Model improvement over baseline: 0.0839\n"
     ]
    }
   ],
   "source": [
    "model, results = diagnose_and_train_xgboost_classifier(X_train, y_resampled, use_time_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e495f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54544\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00     54550\n",
      "   macro avg       0.50      0.50      0.50     54550\n",
      "weighted avg       1.00      1.00      1.00     54550\n",
      "\n",
      "ROC AUC Score:\n",
      "0.7355743375378899\n",
      "Log Loss:\n",
      "0.00670195980775645\n",
      "Confusion Matrix:\n",
      "[[54494    50]\n",
      " [    6     0]]\n"
     ]
    }
   ],
   "source": [
    "y_holdout_pred = model.predict(X_holdout)\n",
    "y_holdout_pred_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, log_loss, confusion_matrix as conf_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_holdout, y_holdout_pred))\n",
    "\n",
    "print(\"ROC AUC Score:\")\n",
    "print(roc_auc_score(y_holdout, y_holdout_pred_proba))\n",
    "\n",
    "print(\"Log Loss:\")\n",
    "print(log_loss(y_holdout, y_holdout_pred_proba))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix(y_holdout, y_holdout_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c08d340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data feature means:\n",
      "dis_slice_0              0.257267\n",
      "dis_slice_1              0.168011\n",
      "dis_slice_2              0.156045\n",
      "dis_slice_3              0.151671\n",
      "dis_slice_4              0.146840\n",
      "                          ...    \n",
      "euclidean_distance_9    69.023011\n",
      "velocity_x_9             0.003761\n",
      "velocity_y_9            -0.003671\n",
      "total_displacement       3.504035\n",
      "path_efficiency          2.458697\n",
      "Length: 520, dtype: float64\n",
      "\n",
      "Holdout data feature means:\n",
      "dis_slice_0              0.277356\n",
      "dis_slice_1              0.174964\n",
      "dis_slice_2              0.157008\n",
      "dis_slice_3              0.150816\n",
      "dis_slice_4              0.148958\n",
      "                          ...    \n",
      "euclidean_distance_9    68.080710\n",
      "velocity_x_9             0.001048\n",
      "velocity_y_9             0.000198\n",
      "total_displacement       3.389112\n",
      "path_efficiency          2.385138\n",
      "Length: 520, dtype: float64\n",
      "Significant difference in dis_slice_0: p=0.003794\n",
      "Significant difference in dis_slice_1: p=0.005982\n",
      "Significant difference in dis_slice_42: p=0.006210\n",
      "Significant difference in dis_slice_53: p=0.000961\n",
      "Significant difference in dis_slice_54: p=0.000937\n",
      "Significant difference in x_slice_0: p=0.000245\n",
      "Significant difference in x_slice_1: p=0.000370\n",
      "Significant difference in x_slice_2: p=0.000318\n",
      "Significant difference in x_slice_3: p=0.000184\n",
      "Significant difference in x_slice_4: p=0.000476\n",
      "Significant difference in x_slice_5: p=0.000359\n",
      "Significant difference in x_slice_6: p=0.000223\n",
      "Significant difference in x_slice_7: p=0.000345\n",
      "Significant difference in x_slice_8: p=0.000685\n",
      "Significant difference in x_slice_9: p=0.001884\n",
      "Significant difference in x_slice_10: p=0.003062\n",
      "Significant difference in x_slice_11: p=0.002172\n",
      "Significant difference in x_slice_12: p=0.003175\n",
      "Significant difference in x_slice_13: p=0.002427\n",
      "Significant difference in x_slice_14: p=0.003018\n",
      "Significant difference in x_slice_15: p=0.002141\n",
      "Significant difference in x_slice_16: p=0.001918\n",
      "Significant difference in x_slice_17: p=0.000997\n",
      "Significant difference in x_slice_18: p=0.001987\n",
      "Significant difference in x_slice_19: p=0.002759\n",
      "Significant difference in x_slice_20: p=0.006392\n",
      "Significant difference in x_slice_22: p=0.004290\n",
      "Significant difference in x_slice_23: p=0.006633\n",
      "Significant difference in o_slice_13: p=0.003221\n",
      "Significant difference in o_slice_16: p=0.008781\n",
      "Significant difference in o_slice_23: p=0.009824\n",
      "Significant difference in o_slice_24: p=0.001394\n",
      "Significant difference in o_slice_25: p=0.001020\n",
      "Significant difference in o_slice_26: p=0.001502\n",
      "Significant difference in o_slice_29: p=0.000992\n",
      "Significant difference in o_slice_30: p=0.000208\n",
      "Significant difference in o_slice_31: p=0.005678\n",
      "Significant difference in o_slice_36: p=0.004610\n",
      "Significant difference in o_slice_39: p=0.008266\n",
      "Significant difference in dis_slice_1_lag1: p=0.003794\n",
      "Significant difference in dis_slice_2_lag1: p=0.005982\n",
      "Significant difference in dis_slice_2_lag2: p=0.003794\n",
      "Significant difference in dis_slice_3_lag2: p=0.005982\n",
      "Significant difference in dis_slice_3_lag3: p=0.003794\n",
      "Significant difference in dis_slice_4_lag3: p=0.005982\n",
      "Significant difference in dis_slice_0_lead1: p=0.005982\n",
      "Significant difference in x_slice_1_lag1: p=0.000245\n",
      "Significant difference in x_slice_2_lag1: p=0.000370\n",
      "Significant difference in x_slice_3_lag1: p=0.000318\n",
      "Significant difference in x_slice_4_lag1: p=0.000184\n",
      "Significant difference in x_slice_5_lag1: p=0.000476\n",
      "Significant difference in x_slice_6_lag1: p=0.000359\n",
      "Significant difference in x_slice_7_lag1: p=0.000223\n",
      "Significant difference in x_slice_8_lag1: p=0.000345\n",
      "Significant difference in x_slice_9_lag1: p=0.000685\n",
      "Significant difference in x_slice_2_lag2: p=0.000245\n",
      "Significant difference in x_slice_3_lag2: p=0.000370\n",
      "Significant difference in x_slice_4_lag2: p=0.000318\n",
      "Significant difference in x_slice_5_lag2: p=0.000184\n",
      "Significant difference in x_slice_6_lag2: p=0.000476\n",
      "Significant difference in x_slice_7_lag2: p=0.000359\n",
      "Significant difference in x_slice_8_lag2: p=0.000223\n",
      "Significant difference in x_slice_9_lag2: p=0.000345\n",
      "Significant difference in x_slice_3_lag3: p=0.000245\n",
      "Significant difference in x_slice_4_lag3: p=0.000370\n",
      "Significant difference in x_slice_5_lag3: p=0.000318\n",
      "Significant difference in x_slice_6_lag3: p=0.000184\n",
      "Significant difference in x_slice_7_lag3: p=0.000476\n",
      "Significant difference in x_slice_8_lag3: p=0.000359\n",
      "Significant difference in x_slice_9_lag3: p=0.000223\n",
      "Significant difference in x_slice_0_lead1: p=0.000370\n",
      "Significant difference in x_slice_1_lead1: p=0.000318\n",
      "Significant difference in x_slice_2_lead1: p=0.000184\n",
      "Significant difference in x_slice_3_lead1: p=0.000476\n",
      "Significant difference in x_slice_4_lead1: p=0.000359\n",
      "Significant difference in x_slice_5_lead1: p=0.000223\n",
      "Significant difference in x_slice_6_lead1: p=0.000345\n",
      "Significant difference in x_slice_7_lead1: p=0.000685\n",
      "Significant difference in x_slice_8_lead1: p=0.001884\n",
      "Significant difference in x_slice_0_lead2: p=0.000318\n",
      "Significant difference in x_slice_1_lead2: p=0.000184\n",
      "Significant difference in x_slice_2_lead2: p=0.000476\n",
      "Significant difference in x_slice_3_lead2: p=0.000359\n",
      "Significant difference in x_slice_4_lead2: p=0.000223\n",
      "Significant difference in x_slice_5_lead2: p=0.000345\n",
      "Significant difference in x_slice_6_lead2: p=0.000685\n",
      "Significant difference in x_slice_7_lead2: p=0.001884\n",
      "Significant difference in dis_early_mean: p=0.000391\n",
      "Significant difference in dis_direction_changes: p=0.005034\n",
      "Significant difference in dis_coefficient_variation: p=0.004678\n",
      "Significant difference in o_std: p=0.002386\n",
      "Significant difference in o_range: p=0.001575\n",
      "Significant difference in o_volatility: p=0.000502\n",
      "Significant difference in x_mean: p=0.000351\n",
      "Significant difference in x_min: p=0.000465\n",
      "Significant difference in x_max: p=0.000131\n",
      "Significant difference in x_early_mean: p=0.000329\n",
      "Significant difference in x_late_mean: p=0.000820\n",
      "Significant difference in x_volatility: p=0.000001\n",
      "Significant difference in x_weighted_mean: p=0.000302\n",
      "Significant difference in y_max: p=0.007648\n",
      "Significant difference in y_volatility: p=0.002349\n",
      "Significant difference in y_direction_changes: p=0.000654\n",
      "Significant difference in dis_o_interaction_0: p=0.001849\n",
      "Significant difference in velocity_y_0: p=0.006919\n",
      "Significant difference in dis_o_interaction_1: p=0.000585\n"
     ]
    }
   ],
   "source": [
    "# Compare feature distributions\n",
    "print(\"Training data feature means:\")\n",
    "print(X_train.mean())\n",
    "print(\"\\nHoldout data feature means:\")\n",
    "print(X_holdout.mean())\n",
    "\n",
    "# Check for significant differences\n",
    "from scipy.stats import ks_2samp\n",
    "for col in X_train.columns:\n",
    "    stat, p_value = ks_2samp(X_train[col], X_holdout[col])\n",
    "    if p_value < 0.01:\n",
    "        print(f\"Significant difference in {col}: p={p_value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c3fddba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dis_slice_0', 'dis_slice_1', 'dis_slice_2', 'dis_slice_3',\n",
       "       'dis_slice_4', 'dis_slice_5', 'dis_slice_6', 'dis_slice_7',\n",
       "       'dis_slice_8', 'dis_slice_9',\n",
       "       ...\n",
       "       'euclidean_distance_8', 'velocity_x_8', 'velocity_y_8',\n",
       "       'x_y_interaction_9', 'dis_o_interaction_9', 'euclidean_distance_9',\n",
       "       'velocity_x_9', 'velocity_y_9', 'total_displacement',\n",
       "       'path_efficiency'],\n",
       "      dtype='object', length=520)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cced61",
   "metadata": {},
   "source": [
    "### try again with our resampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcd254f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.16570\n",
      "[1]\tvalidation_0-logloss:0.15346\n",
      "[2]\tvalidation_0-logloss:0.14296\n",
      "[3]\tvalidation_0-logloss:0.13299\n",
      "[4]\tvalidation_0-logloss:0.12517\n",
      "[5]\tvalidation_0-logloss:0.11673\n",
      "[6]\tvalidation_0-logloss:0.11053\n",
      "[7]\tvalidation_0-logloss:0.10359\n",
      "[8]\tvalidation_0-logloss:0.09765\n",
      "[9]\tvalidation_0-logloss:0.09221\n",
      "[10]\tvalidation_0-logloss:0.08805\n",
      "[11]\tvalidation_0-logloss:0.08341\n",
      "[12]\tvalidation_0-logloss:0.07867\n",
      "[13]\tvalidation_0-logloss:0.07417\n",
      "[14]\tvalidation_0-logloss:0.07133\n",
      "[15]\tvalidation_0-logloss:0.06870\n",
      "[16]\tvalidation_0-logloss:0.06538\n",
      "[17]\tvalidation_0-logloss:0.06229\n",
      "[18]\tvalidation_0-logloss:0.06026\n",
      "[19]\tvalidation_0-logloss:0.05698\n",
      "[20]\tvalidation_0-logloss:0.05418\n",
      "[21]\tvalidation_0-logloss:0.05219\n",
      "[22]\tvalidation_0-logloss:0.05039\n",
      "[23]\tvalidation_0-logloss:0.04791\n",
      "[24]\tvalidation_0-logloss:0.04681\n",
      "[25]\tvalidation_0-logloss:0.04465\n",
      "[26]\tvalidation_0-logloss:0.04337\n",
      "[27]\tvalidation_0-logloss:0.04235\n",
      "[28]\tvalidation_0-logloss:0.04073\n",
      "[29]\tvalidation_0-logloss:0.03990\n",
      "[30]\tvalidation_0-logloss:0.03866\n",
      "[31]\tvalidation_0-logloss:0.03758\n",
      "[32]\tvalidation_0-logloss:0.03631\n",
      "[33]\tvalidation_0-logloss:0.03491\n",
      "[34]\tvalidation_0-logloss:0.03371\n",
      "[35]\tvalidation_0-logloss:0.03231\n",
      "[36]\tvalidation_0-logloss:0.03121\n",
      "[37]\tvalidation_0-logloss:0.03022\n",
      "[38]\tvalidation_0-logloss:0.02945\n",
      "[39]\tvalidation_0-logloss:0.02819\n",
      "[40]\tvalidation_0-logloss:0.02746\n",
      "[41]\tvalidation_0-logloss:0.02657\n",
      "[42]\tvalidation_0-logloss:0.02588\n",
      "[43]\tvalidation_0-logloss:0.02522\n",
      "[44]\tvalidation_0-logloss:0.02489\n",
      "[45]\tvalidation_0-logloss:0.02415\n",
      "[46]\tvalidation_0-logloss:0.02353\n",
      "[47]\tvalidation_0-logloss:0.02272\n",
      "[48]\tvalidation_0-logloss:0.02192\n",
      "[49]\tvalidation_0-logloss:0.02124\n",
      "[50]\tvalidation_0-logloss:0.02061\n",
      "[51]\tvalidation_0-logloss:0.02011\n",
      "[52]\tvalidation_0-logloss:0.01978\n",
      "[53]\tvalidation_0-logloss:0.01929\n",
      "[54]\tvalidation_0-logloss:0.01896\n",
      "[55]\tvalidation_0-logloss:0.01843\n",
      "[56]\tvalidation_0-logloss:0.01789\n",
      "[57]\tvalidation_0-logloss:0.01740\n",
      "[58]\tvalidation_0-logloss:0.01708\n",
      "[59]\tvalidation_0-logloss:0.01689\n",
      "[60]\tvalidation_0-logloss:0.01660\n",
      "[61]\tvalidation_0-logloss:0.01610\n",
      "[62]\tvalidation_0-logloss:0.01580\n",
      "[63]\tvalidation_0-logloss:0.01545\n",
      "[64]\tvalidation_0-logloss:0.01526\n",
      "[65]\tvalidation_0-logloss:0.01498\n",
      "[66]\tvalidation_0-logloss:0.01464\n",
      "[67]\tvalidation_0-logloss:0.01441\n",
      "[68]\tvalidation_0-logloss:0.01407\n",
      "[69]\tvalidation_0-logloss:0.01376\n",
      "[70]\tvalidation_0-logloss:0.01354\n",
      "[71]\tvalidation_0-logloss:0.01330\n",
      "[72]\tvalidation_0-logloss:0.01302\n",
      "[73]\tvalidation_0-logloss:0.01285\n",
      "[74]\tvalidation_0-logloss:0.01259\n",
      "[75]\tvalidation_0-logloss:0.01234\n",
      "[76]\tvalidation_0-logloss:0.01218\n",
      "[77]\tvalidation_0-logloss:0.01199\n",
      "[78]\tvalidation_0-logloss:0.01174\n",
      "[79]\tvalidation_0-logloss:0.01154\n",
      "[80]\tvalidation_0-logloss:0.01145\n",
      "[81]\tvalidation_0-logloss:0.01129\n",
      "[82]\tvalidation_0-logloss:0.01118\n",
      "[83]\tvalidation_0-logloss:0.01094\n",
      "[84]\tvalidation_0-logloss:0.01080\n",
      "[85]\tvalidation_0-logloss:0.01065\n",
      "[86]\tvalidation_0-logloss:0.01052\n",
      "[87]\tvalidation_0-logloss:0.01043\n",
      "[88]\tvalidation_0-logloss:0.01032\n",
      "[89]\tvalidation_0-logloss:0.01019\n",
      "[90]\tvalidation_0-logloss:0.01013\n",
      "[91]\tvalidation_0-logloss:0.01001\n",
      "[92]\tvalidation_0-logloss:0.00995\n",
      "[93]\tvalidation_0-logloss:0.00982\n",
      "[94]\tvalidation_0-logloss:0.00969\n",
      "[95]\tvalidation_0-logloss:0.00958\n",
      "[96]\tvalidation_0-logloss:0.00951\n",
      "[97]\tvalidation_0-logloss:0.00947\n",
      "[98]\tvalidation_0-logloss:0.00942\n",
      "[99]\tvalidation_0-logloss:0.00941\n",
      "[100]\tvalidation_0-logloss:0.00937\n",
      "[101]\tvalidation_0-logloss:0.00926\n",
      "[102]\tvalidation_0-logloss:0.00916\n",
      "[103]\tvalidation_0-logloss:0.00909\n",
      "[104]\tvalidation_0-logloss:0.00900\n",
      "[105]\tvalidation_0-logloss:0.00894\n",
      "[106]\tvalidation_0-logloss:0.00887\n",
      "[107]\tvalidation_0-logloss:0.00882\n",
      "[108]\tvalidation_0-logloss:0.00874\n",
      "[109]\tvalidation_0-logloss:0.00867\n",
      "[110]\tvalidation_0-logloss:0.00860\n",
      "[111]\tvalidation_0-logloss:0.00858\n",
      "[112]\tvalidation_0-logloss:0.00851\n",
      "[113]\tvalidation_0-logloss:0.00843\n",
      "[114]\tvalidation_0-logloss:0.00836\n",
      "[115]\tvalidation_0-logloss:0.00827\n",
      "[116]\tvalidation_0-logloss:0.00822\n",
      "[117]\tvalidation_0-logloss:0.00817\n",
      "[118]\tvalidation_0-logloss:0.00815\n",
      "[119]\tvalidation_0-logloss:0.00806\n",
      "[120]\tvalidation_0-logloss:0.00801\n",
      "[121]\tvalidation_0-logloss:0.00794\n",
      "[122]\tvalidation_0-logloss:0.00787\n",
      "[123]\tvalidation_0-logloss:0.00784\n",
      "[124]\tvalidation_0-logloss:0.00781\n",
      "[125]\tvalidation_0-logloss:0.00778\n",
      "[126]\tvalidation_0-logloss:0.00773\n",
      "[127]\tvalidation_0-logloss:0.00770\n",
      "[128]\tvalidation_0-logloss:0.00766\n",
      "[129]\tvalidation_0-logloss:0.00762\n",
      "[130]\tvalidation_0-logloss:0.00757\n",
      "[131]\tvalidation_0-logloss:0.00753\n",
      "[132]\tvalidation_0-logloss:0.00749\n",
      "[133]\tvalidation_0-logloss:0.00745\n",
      "[134]\tvalidation_0-logloss:0.00741\n",
      "[135]\tvalidation_0-logloss:0.00740\n",
      "[136]\tvalidation_0-logloss:0.00735\n",
      "[137]\tvalidation_0-logloss:0.00729\n",
      "[138]\tvalidation_0-logloss:0.00725\n",
      "[139]\tvalidation_0-logloss:0.00723\n",
      "[140]\tvalidation_0-logloss:0.00721\n",
      "[141]\tvalidation_0-logloss:0.00719\n",
      "[142]\tvalidation_0-logloss:0.00714\n",
      "[143]\tvalidation_0-logloss:0.00712\n",
      "[144]\tvalidation_0-logloss:0.00711\n",
      "[145]\tvalidation_0-logloss:0.00707\n",
      "[146]\tvalidation_0-logloss:0.00703\n",
      "[147]\tvalidation_0-logloss:0.00701\n",
      "[148]\tvalidation_0-logloss:0.00698\n",
      "[149]\tvalidation_0-logloss:0.00698\n",
      "[150]\tvalidation_0-logloss:0.00694\n",
      "[151]\tvalidation_0-logloss:0.00693\n",
      "[152]\tvalidation_0-logloss:0.00691\n",
      "[153]\tvalidation_0-logloss:0.00688\n",
      "[154]\tvalidation_0-logloss:0.00687\n",
      "[155]\tvalidation_0-logloss:0.00685\n",
      "[156]\tvalidation_0-logloss:0.00681\n",
      "[157]\tvalidation_0-logloss:0.00679\n",
      "[158]\tvalidation_0-logloss:0.00676\n",
      "[159]\tvalidation_0-logloss:0.00673\n",
      "[160]\tvalidation_0-logloss:0.00670\n",
      "[161]\tvalidation_0-logloss:0.00668\n",
      "[162]\tvalidation_0-logloss:0.00665\n",
      "[163]\tvalidation_0-logloss:0.00661\n",
      "[164]\tvalidation_0-logloss:0.00658\n",
      "[165]\tvalidation_0-logloss:0.00655\n",
      "[166]\tvalidation_0-logloss:0.00656\n",
      "[167]\tvalidation_0-logloss:0.00652\n",
      "[168]\tvalidation_0-logloss:0.00650\n",
      "[169]\tvalidation_0-logloss:0.00650\n",
      "[170]\tvalidation_0-logloss:0.00647\n",
      "[171]\tvalidation_0-logloss:0.00647\n",
      "[172]\tvalidation_0-logloss:0.00647\n",
      "[173]\tvalidation_0-logloss:0.00644\n",
      "[174]\tvalidation_0-logloss:0.00642\n",
      "[175]\tvalidation_0-logloss:0.00644\n",
      "[176]\tvalidation_0-logloss:0.00641\n",
      "[177]\tvalidation_0-logloss:0.00640\n",
      "[178]\tvalidation_0-logloss:0.00639\n",
      "[179]\tvalidation_0-logloss:0.00637\n",
      "[180]\tvalidation_0-logloss:0.00634\n",
      "[181]\tvalidation_0-logloss:0.00631\n",
      "[182]\tvalidation_0-logloss:0.00629\n",
      "[183]\tvalidation_0-logloss:0.00626\n",
      "[184]\tvalidation_0-logloss:0.00625\n",
      "[185]\tvalidation_0-logloss:0.00625\n",
      "[186]\tvalidation_0-logloss:0.00623\n",
      "[187]\tvalidation_0-logloss:0.00622\n",
      "[188]\tvalidation_0-logloss:0.00620\n",
      "[189]\tvalidation_0-logloss:0.00618\n",
      "[190]\tvalidation_0-logloss:0.00616\n",
      "[191]\tvalidation_0-logloss:0.00614\n",
      "[192]\tvalidation_0-logloss:0.00613\n",
      "[193]\tvalidation_0-logloss:0.00614\n",
      "[194]\tvalidation_0-logloss:0.00613\n",
      "[195]\tvalidation_0-logloss:0.00613\n",
      "[196]\tvalidation_0-logloss:0.00612\n",
      "[197]\tvalidation_0-logloss:0.00610\n",
      "[198]\tvalidation_0-logloss:0.00609\n",
      "[199]\tvalidation_0-logloss:0.00609\n",
      "[200]\tvalidation_0-logloss:0.00608\n",
      "[201]\tvalidation_0-logloss:0.00607\n",
      "[202]\tvalidation_0-logloss:0.00607\n",
      "[203]\tvalidation_0-logloss:0.00606\n",
      "[204]\tvalidation_0-logloss:0.00605\n",
      "[205]\tvalidation_0-logloss:0.00604\n",
      "[206]\tvalidation_0-logloss:0.00603\n",
      "[207]\tvalidation_0-logloss:0.00602\n",
      "[208]\tvalidation_0-logloss:0.00601\n",
      "[209]\tvalidation_0-logloss:0.00601\n",
      "[210]\tvalidation_0-logloss:0.00602\n",
      "[211]\tvalidation_0-logloss:0.00601\n",
      "[212]\tvalidation_0-logloss:0.00600\n",
      "[213]\tvalidation_0-logloss:0.00600\n",
      "[214]\tvalidation_0-logloss:0.00597\n",
      "[215]\tvalidation_0-logloss:0.00597\n",
      "[216]\tvalidation_0-logloss:0.00597\n",
      "[217]\tvalidation_0-logloss:0.00596\n",
      "[218]\tvalidation_0-logloss:0.00595\n",
      "[219]\tvalidation_0-logloss:0.00596\n",
      "[220]\tvalidation_0-logloss:0.00593\n",
      "[221]\tvalidation_0-logloss:0.00593\n",
      "[222]\tvalidation_0-logloss:0.00594\n",
      "[223]\tvalidation_0-logloss:0.00593\n",
      "[224]\tvalidation_0-logloss:0.00590\n",
      "[225]\tvalidation_0-logloss:0.00589\n",
      "[226]\tvalidation_0-logloss:0.00588\n",
      "[227]\tvalidation_0-logloss:0.00586\n",
      "[228]\tvalidation_0-logloss:0.00585\n",
      "[229]\tvalidation_0-logloss:0.00583\n",
      "[230]\tvalidation_0-logloss:0.00584\n",
      "[231]\tvalidation_0-logloss:0.00583\n",
      "[232]\tvalidation_0-logloss:0.00583\n",
      "[233]\tvalidation_0-logloss:0.00581\n",
      "[234]\tvalidation_0-logloss:0.00579\n",
      "[235]\tvalidation_0-logloss:0.00577\n",
      "[236]\tvalidation_0-logloss:0.00577\n",
      "[237]\tvalidation_0-logloss:0.00577\n",
      "[238]\tvalidation_0-logloss:0.00576\n",
      "[239]\tvalidation_0-logloss:0.00577\n",
      "[240]\tvalidation_0-logloss:0.00576\n",
      "[241]\tvalidation_0-logloss:0.00576\n",
      "[242]\tvalidation_0-logloss:0.00573\n",
      "[243]\tvalidation_0-logloss:0.00573\n",
      "[244]\tvalidation_0-logloss:0.00572\n",
      "[245]\tvalidation_0-logloss:0.00570\n",
      "[246]\tvalidation_0-logloss:0.00569\n",
      "[247]\tvalidation_0-logloss:0.00569\n",
      "[248]\tvalidation_0-logloss:0.00568\n",
      "[249]\tvalidation_0-logloss:0.00567\n",
      "[250]\tvalidation_0-logloss:0.00567\n",
      "[251]\tvalidation_0-logloss:0.00566\n",
      "[252]\tvalidation_0-logloss:0.00564\n",
      "[253]\tvalidation_0-logloss:0.00565\n",
      "[254]\tvalidation_0-logloss:0.00565\n",
      "[255]\tvalidation_0-logloss:0.00565\n",
      "[256]\tvalidation_0-logloss:0.00564\n",
      "[257]\tvalidation_0-logloss:0.00565\n",
      "[258]\tvalidation_0-logloss:0.00563\n",
      "[259]\tvalidation_0-logloss:0.00565\n",
      "[260]\tvalidation_0-logloss:0.00563\n",
      "[261]\tvalidation_0-logloss:0.00561\n",
      "[262]\tvalidation_0-logloss:0.00561\n",
      "[263]\tvalidation_0-logloss:0.00560\n",
      "[264]\tvalidation_0-logloss:0.00559\n",
      "[265]\tvalidation_0-logloss:0.00558\n",
      "[266]\tvalidation_0-logloss:0.00558\n",
      "[267]\tvalidation_0-logloss:0.00557\n",
      "[268]\tvalidation_0-logloss:0.00558\n",
      "[269]\tvalidation_0-logloss:0.00557\n",
      "[270]\tvalidation_0-logloss:0.00557\n",
      "[271]\tvalidation_0-logloss:0.00557\n",
      "[272]\tvalidation_0-logloss:0.00557\n",
      "[273]\tvalidation_0-logloss:0.00557\n",
      "[274]\tvalidation_0-logloss:0.00556\n",
      "[275]\tvalidation_0-logloss:0.00556\n",
      "[276]\tvalidation_0-logloss:0.00556\n",
      "[277]\tvalidation_0-logloss:0.00553\n",
      "[278]\tvalidation_0-logloss:0.00554\n",
      "[279]\tvalidation_0-logloss:0.00553\n",
      "[280]\tvalidation_0-logloss:0.00553\n",
      "[281]\tvalidation_0-logloss:0.00551\n",
      "[282]\tvalidation_0-logloss:0.00550\n",
      "[283]\tvalidation_0-logloss:0.00550\n",
      "[284]\tvalidation_0-logloss:0.00548\n",
      "[285]\tvalidation_0-logloss:0.00546\n",
      "[286]\tvalidation_0-logloss:0.00545\n",
      "[287]\tvalidation_0-logloss:0.00545\n",
      "[288]\tvalidation_0-logloss:0.00544\n",
      "[289]\tvalidation_0-logloss:0.00545\n",
      "[290]\tvalidation_0-logloss:0.00544\n",
      "[291]\tvalidation_0-logloss:0.00543\n",
      "[292]\tvalidation_0-logloss:0.00542\n",
      "[293]\tvalidation_0-logloss:0.00541\n",
      "[294]\tvalidation_0-logloss:0.00542\n",
      "[295]\tvalidation_0-logloss:0.00543\n",
      "[296]\tvalidation_0-logloss:0.00543\n",
      "[297]\tvalidation_0-logloss:0.00544\n",
      "[298]\tvalidation_0-logloss:0.00544\n",
      "[299]\tvalidation_0-logloss:0.00545\n",
      "[300]\tvalidation_0-logloss:0.00545\n",
      "[301]\tvalidation_0-logloss:0.00545\n",
      "[302]\tvalidation_0-logloss:0.00545\n",
      "[303]\tvalidation_0-logloss:0.00546\n",
      "[304]\tvalidation_0-logloss:0.00544\n",
      "[305]\tvalidation_0-logloss:0.00544\n",
      "[306]\tvalidation_0-logloss:0.00543\n",
      "[307]\tvalidation_0-logloss:0.00543\n",
      "[308]\tvalidation_0-logloss:0.00544\n",
      "[309]\tvalidation_0-logloss:0.00544\n",
      "[310]\tvalidation_0-logloss:0.00545\n",
      "[311]\tvalidation_0-logloss:0.00545\n",
      "[312]\tvalidation_0-logloss:0.00543\n",
      "[313]\tvalidation_0-logloss:0.00543\n",
      "[314]\tvalidation_0-logloss:0.00542\n",
      "[315]\tvalidation_0-logloss:0.00543\n",
      "[316]\tvalidation_0-logloss:0.00541\n",
      "[317]\tvalidation_0-logloss:0.00542\n",
      "[318]\tvalidation_0-logloss:0.00542\n",
      "[319]\tvalidation_0-logloss:0.00542\n",
      "[320]\tvalidation_0-logloss:0.00541\n",
      "[321]\tvalidation_0-logloss:0.00540\n",
      "[322]\tvalidation_0-logloss:0.00539\n",
      "[323]\tvalidation_0-logloss:0.00540\n",
      "[324]\tvalidation_0-logloss:0.00541\n",
      "[325]\tvalidation_0-logloss:0.00540\n",
      "[326]\tvalidation_0-logloss:0.00541\n",
      "[327]\tvalidation_0-logloss:0.00540\n",
      "[328]\tvalidation_0-logloss:0.00539\n",
      "[329]\tvalidation_0-logloss:0.00539\n",
      "[330]\tvalidation_0-logloss:0.00539\n",
      "[331]\tvalidation_0-logloss:0.00539\n",
      "[332]\tvalidation_0-logloss:0.00540\n",
      "[333]\tvalidation_0-logloss:0.00540\n",
      "[334]\tvalidation_0-logloss:0.00540\n",
      "[335]\tvalidation_0-logloss:0.00539\n",
      "[336]\tvalidation_0-logloss:0.00538\n",
      "[337]\tvalidation_0-logloss:0.00538\n",
      "[338]\tvalidation_0-logloss:0.00539\n",
      "[339]\tvalidation_0-logloss:0.00539\n",
      "[340]\tvalidation_0-logloss:0.00538\n",
      "[341]\tvalidation_0-logloss:0.00538\n",
      "[342]\tvalidation_0-logloss:0.00538\n",
      "[343]\tvalidation_0-logloss:0.00537\n",
      "[344]\tvalidation_0-logloss:0.00537\n",
      "[345]\tvalidation_0-logloss:0.00536\n",
      "[346]\tvalidation_0-logloss:0.00537\n",
      "[347]\tvalidation_0-logloss:0.00537\n",
      "[348]\tvalidation_0-logloss:0.00538\n",
      "[349]\tvalidation_0-logloss:0.00537\n",
      "[350]\tvalidation_0-logloss:0.00537\n",
      "[351]\tvalidation_0-logloss:0.00536\n",
      "[352]\tvalidation_0-logloss:0.00536\n",
      "[353]\tvalidation_0-logloss:0.00536\n",
      "[354]\tvalidation_0-logloss:0.00535\n",
      "[355]\tvalidation_0-logloss:0.00534\n",
      "[356]\tvalidation_0-logloss:0.00535\n",
      "[357]\tvalidation_0-logloss:0.00534\n",
      "[358]\tvalidation_0-logloss:0.00533\n",
      "[359]\tvalidation_0-logloss:0.00533\n",
      "[360]\tvalidation_0-logloss:0.00531\n",
      "[361]\tvalidation_0-logloss:0.00530\n",
      "[362]\tvalidation_0-logloss:0.00529\n",
      "[363]\tvalidation_0-logloss:0.00528\n",
      "[364]\tvalidation_0-logloss:0.00528\n",
      "[365]\tvalidation_0-logloss:0.00527\n",
      "[366]\tvalidation_0-logloss:0.00528\n",
      "[367]\tvalidation_0-logloss:0.00527\n",
      "[368]\tvalidation_0-logloss:0.00527\n",
      "[369]\tvalidation_0-logloss:0.00527\n",
      "[370]\tvalidation_0-logloss:0.00526\n",
      "[371]\tvalidation_0-logloss:0.00526\n",
      "[372]\tvalidation_0-logloss:0.00528\n",
      "[373]\tvalidation_0-logloss:0.00527\n",
      "[374]\tvalidation_0-logloss:0.00528\n",
      "[375]\tvalidation_0-logloss:0.00527\n",
      "[376]\tvalidation_0-logloss:0.00526\n",
      "[377]\tvalidation_0-logloss:0.00525\n",
      "[378]\tvalidation_0-logloss:0.00525\n",
      "[379]\tvalidation_0-logloss:0.00525\n",
      "[380]\tvalidation_0-logloss:0.00527\n",
      "[381]\tvalidation_0-logloss:0.00526\n",
      "[382]\tvalidation_0-logloss:0.00527\n",
      "[383]\tvalidation_0-logloss:0.00527\n",
      "[384]\tvalidation_0-logloss:0.00527\n",
      "[385]\tvalidation_0-logloss:0.00526\n",
      "[386]\tvalidation_0-logloss:0.00526\n",
      "[387]\tvalidation_0-logloss:0.00525\n",
      "[388]\tvalidation_0-logloss:0.00524\n",
      "[389]\tvalidation_0-logloss:0.00524\n",
      "[390]\tvalidation_0-logloss:0.00523\n",
      "[391]\tvalidation_0-logloss:0.00524\n",
      "[392]\tvalidation_0-logloss:0.00524\n",
      "[393]\tvalidation_0-logloss:0.00524\n",
      "[394]\tvalidation_0-logloss:0.00524\n",
      "[395]\tvalidation_0-logloss:0.00526\n",
      "[396]\tvalidation_0-logloss:0.00525\n",
      "[397]\tvalidation_0-logloss:0.00524\n",
      "[398]\tvalidation_0-logloss:0.00522\n",
      "[399]\tvalidation_0-logloss:0.00522\n",
      "[400]\tvalidation_0-logloss:0.00520\n",
      "[401]\tvalidation_0-logloss:0.00520\n",
      "[402]\tvalidation_0-logloss:0.00520\n",
      "[403]\tvalidation_0-logloss:0.00520\n",
      "[404]\tvalidation_0-logloss:0.00521\n",
      "[405]\tvalidation_0-logloss:0.00521\n",
      "[406]\tvalidation_0-logloss:0.00521\n",
      "[407]\tvalidation_0-logloss:0.00521\n",
      "[408]\tvalidation_0-logloss:0.00520\n",
      "[409]\tvalidation_0-logloss:0.00520\n",
      "[410]\tvalidation_0-logloss:0.00520\n",
      "[411]\tvalidation_0-logloss:0.00519\n",
      "[412]\tvalidation_0-logloss:0.00518\n",
      "[413]\tvalidation_0-logloss:0.00518\n",
      "[414]\tvalidation_0-logloss:0.00519\n",
      "[415]\tvalidation_0-logloss:0.00518\n",
      "[416]\tvalidation_0-logloss:0.00518\n",
      "[417]\tvalidation_0-logloss:0.00518\n",
      "[418]\tvalidation_0-logloss:0.00518\n",
      "[419]\tvalidation_0-logloss:0.00515\n",
      "[420]\tvalidation_0-logloss:0.00515\n",
      "[421]\tvalidation_0-logloss:0.00514\n",
      "[422]\tvalidation_0-logloss:0.00514\n",
      "[423]\tvalidation_0-logloss:0.00513\n",
      "[424]\tvalidation_0-logloss:0.00515\n",
      "[425]\tvalidation_0-logloss:0.00516\n",
      "[426]\tvalidation_0-logloss:0.00517\n",
      "[427]\tvalidation_0-logloss:0.00516\n",
      "[428]\tvalidation_0-logloss:0.00517\n",
      "[429]\tvalidation_0-logloss:0.00517\n",
      "[430]\tvalidation_0-logloss:0.00516\n",
      "[431]\tvalidation_0-logloss:0.00515\n",
      "[432]\tvalidation_0-logloss:0.00514\n",
      "[433]\tvalidation_0-logloss:0.00514\n",
      "[434]\tvalidation_0-logloss:0.00514\n",
      "[435]\tvalidation_0-logloss:0.00514\n",
      "[436]\tvalidation_0-logloss:0.00513\n",
      "[437]\tvalidation_0-logloss:0.00514\n",
      "[438]\tvalidation_0-logloss:0.00515\n",
      "[439]\tvalidation_0-logloss:0.00517\n",
      "[440]\tvalidation_0-logloss:0.00517\n",
      "[441]\tvalidation_0-logloss:0.00515\n",
      "[442]\tvalidation_0-logloss:0.00515\n",
      "[443]\tvalidation_0-logloss:0.00515\n",
      "[444]\tvalidation_0-logloss:0.00516\n",
      "[445]\tvalidation_0-logloss:0.00516\n",
      "[446]\tvalidation_0-logloss:0.00516\n",
      "[447]\tvalidation_0-logloss:0.00517\n",
      "[448]\tvalidation_0-logloss:0.00518\n",
      "[449]\tvalidation_0-logloss:0.00518\n",
      "[450]\tvalidation_0-logloss:0.00518\n",
      "[451]\tvalidation_0-logloss:0.00518\n",
      "[452]\tvalidation_0-logloss:0.00516\n",
      "[453]\tvalidation_0-logloss:0.00516\n",
      "[454]\tvalidation_0-logloss:0.00515\n",
      "[455]\tvalidation_0-logloss:0.00515\n",
      "[456]\tvalidation_0-logloss:0.00515\n",
      "[457]\tvalidation_0-logloss:0.00515\n",
      "[458]\tvalidation_0-logloss:0.00515\n",
      "[459]\tvalidation_0-logloss:0.00517\n",
      "[460]\tvalidation_0-logloss:0.00517\n",
      "[461]\tvalidation_0-logloss:0.00517\n",
      "[462]\tvalidation_0-logloss:0.00518\n",
      "[463]\tvalidation_0-logloss:0.00518\n",
      "[464]\tvalidation_0-logloss:0.00518\n",
      "[465]\tvalidation_0-logloss:0.00517\n",
      "[466]\tvalidation_0-logloss:0.00518\n",
      "[467]\tvalidation_0-logloss:0.00518\n",
      "[468]\tvalidation_0-logloss:0.00517\n",
      "[469]\tvalidation_0-logloss:0.00516\n",
      "[470]\tvalidation_0-logloss:0.00516\n",
      "[471]\tvalidation_0-logloss:0.00515\n",
      "[472]\tvalidation_0-logloss:0.00516\n",
      "[473]\tvalidation_0-logloss:0.00518\n",
      "[474]\tvalidation_0-logloss:0.00519\n",
      "[475]\tvalidation_0-logloss:0.00519\n",
      "[476]\tvalidation_0-logloss:0.00518\n",
      "[477]\tvalidation_0-logloss:0.00517\n",
      "[478]\tvalidation_0-logloss:0.00517\n",
      "[479]\tvalidation_0-logloss:0.00517\n",
      "[480]\tvalidation_0-logloss:0.00516\n",
      "[481]\tvalidation_0-logloss:0.00517\n",
      "[482]\tvalidation_0-logloss:0.00515\n",
      "[483]\tvalidation_0-logloss:0.00515\n",
      "[484]\tvalidation_0-logloss:0.00514\n",
      "[485]\tvalidation_0-logloss:0.00514\n",
      "[486]\tvalidation_0-logloss:0.00514\n",
      "[487]\tvalidation_0-logloss:0.00514\n",
      "[488]\tvalidation_0-logloss:0.00515\n",
      "[489]\tvalidation_0-logloss:0.00516\n",
      "[490]\tvalidation_0-logloss:0.00515\n",
      "[491]\tvalidation_0-logloss:0.00516\n",
      "[492]\tvalidation_0-logloss:0.00516\n",
      "[493]\tvalidation_0-logloss:0.00516\n",
      "[494]\tvalidation_0-logloss:0.00516\n",
      "[495]\tvalidation_0-logloss:0.00516\n",
      "[496]\tvalidation_0-logloss:0.00515\n",
      "[497]\tvalidation_0-logloss:0.00515\n",
      "[498]\tvalidation_0-logloss:0.00515\n",
      "[499]\tvalidation_0-logloss:0.00516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=1,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=1,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',  # Use GPU acceleration\n",
    "    tree_method='hist',  # Required for GPU\n",
    "    n_jobs=1  # Use 1 job when using GPU\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_resampled, eval_set=[(X_holdout, y_holdout)],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca62cfda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     54544\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           1.00     54550\n",
      "   macro avg       0.50      0.50      0.50     54550\n",
      "weighted avg       1.00      1.00      1.00     54550\n",
      "\n",
      "ROC AUC Score:\n",
      "0.6701989830839934\n",
      "Log Loss:\n",
      "0.005156602041139079\n",
      "Confusion Matrix:\n",
      "[[54516    28]\n",
      " [    6     0]]\n",
      "Feature Importances:\n",
      "                   feature  importance\n",
      "333         x_slice_4_lag2    0.085737\n",
      "342         x_slice_6_lag3    0.028481\n",
      "373         y_slice_3_lag2    0.027985\n",
      "514    dis_o_interaction_9    0.023468\n",
      "408                dis_min    0.023115\n",
      "243       dis_slice_4_lag1    0.020086\n",
      "417  dis_direction_changes    0.017937\n",
      "73              x_slice_13    0.015915\n",
      "284         o_slice_4_lag1    0.015676\n",
      "116             x_slice_56    0.014406\n"
     ]
    }
   ],
   "source": [
    "y_holdout_pred = model.predict(X_holdout)\n",
    "y_holdout_pred_proba = model.predict_proba(X_holdout)[:, 1]\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_holdout, y_holdout_pred))\n",
    "print(\"ROC AUC Score:\")\n",
    "print(roc_auc_score(y_holdout, y_holdout_pred_proba))\n",
    "print(\"Log Loss:\")\n",
    "print(log_loss(y_holdout, y_holdout_pred_proba))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix(y_holdout, y_holdout_pred))\n",
    "print(\"Feature Importances:\")\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(feature_importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52f33d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability scores for the 6 actual concussions:\n",
      "[0.   0.   0.   0.   0.01 0.  ]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Probability scores for the 6 actual concussions:\")\n",
    "print(y_holdout_pred_proba[y_holdout == 1].round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "354dc223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     19\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m     20\u001b[39m     estimator=xgb_model,\n\u001b[32m     21\u001b[39m     param_distributions=param_dist,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     n_jobs=\u001b[32m1\u001b[39m   \u001b[38;5;66;03m# Use all available cores\u001b[39;00m\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Fit the search to your data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_resampled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Get the best parameters and best score\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest parameters found: \u001b[39m\u001b[33m\"\u001b[39m, random_search.best_params_)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/sklearn.py:1599\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[39m\n\u001b[32m   1579\u001b[39m model, metric, params = \u001b[38;5;28mself\u001b[39m._configure_fit(xgb_model, params)\n\u001b[32m   1580\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1581\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1582\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1596\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1597\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1599\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1600\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1601\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1602\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1611\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1614\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/training.py:181\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/rapids-25.02/lib/python3.12/site-packages/xgboost/core.py:2101\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2100\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2101\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m     )\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the parameter distribution\n",
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = XGBClassifier(objective='binary:logistic', device='cuda', tree_method='hist', n_jobs=1)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=50,  # Number of parameter settings that are sampled\n",
    "    scoring='roc_auc', # Or 'accuracy', 'f1', etc.\n",
    "    cv=5,       # Number of cross-validation folds\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1   # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the search to your data\n",
    "random_search.fit(X_train, y_resampled)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best ROC AUC score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7947f7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.91537\n",
      "[1]\tvalidation_0-auc:0.94467\n",
      "[2]\tvalidation_0-auc:0.95298\n",
      "[3]\tvalidation_0-auc:0.97536\n",
      "[4]\tvalidation_0-auc:0.97302\n",
      "[5]\tvalidation_0-auc:0.96835\n",
      "[6]\tvalidation_0-auc:0.97498\n",
      "[7]\tvalidation_0-auc:0.97734\n",
      "[8]\tvalidation_0-auc:0.97602\n",
      "[9]\tvalidation_0-auc:0.97890\n",
      "[10]\tvalidation_0-auc:0.98586\n",
      "[11]\tvalidation_0-auc:0.98516\n",
      "[12]\tvalidation_0-auc:0.98318\n",
      "[13]\tvalidation_0-auc:0.98532\n",
      "[14]\tvalidation_0-auc:0.98668\n",
      "[15]\tvalidation_0-auc:0.98608\n",
      "[16]\tvalidation_0-auc:0.98684\n",
      "[17]\tvalidation_0-auc:0.98738\n",
      "[18]\tvalidation_0-auc:0.98667\n",
      "[19]\tvalidation_0-auc:0.98828\n",
      "[20]\tvalidation_0-auc:0.98735\n",
      "[21]\tvalidation_0-auc:0.98835\n",
      "[22]\tvalidation_0-auc:0.98979\n",
      "[23]\tvalidation_0-auc:0.98882\n",
      "[24]\tvalidation_0-auc:0.98898\n",
      "[25]\tvalidation_0-auc:0.98893\n",
      "[26]\tvalidation_0-auc:0.98900\n",
      "[27]\tvalidation_0-auc:0.98803\n",
      "[28]\tvalidation_0-auc:0.98755\n",
      "[29]\tvalidation_0-auc:0.98791\n",
      "[30]\tvalidation_0-auc:0.98837\n",
      "[31]\tvalidation_0-auc:0.98782\n",
      "[32]\tvalidation_0-auc:0.98806\n",
      "[33]\tvalidation_0-auc:0.98861\n",
      "[34]\tvalidation_0-auc:0.98905\n",
      "[35]\tvalidation_0-auc:0.98954\n",
      "[36]\tvalidation_0-auc:0.99002\n",
      "[37]\tvalidation_0-auc:0.98977\n",
      "[38]\tvalidation_0-auc:0.98928\n",
      "[39]\tvalidation_0-auc:0.98923\n",
      "[40]\tvalidation_0-auc:0.98938\n",
      "[41]\tvalidation_0-auc:0.98927\n",
      "[42]\tvalidation_0-auc:0.99000\n",
      "[43]\tvalidation_0-auc:0.99024\n",
      "[44]\tvalidation_0-auc:0.99003\n",
      "[45]\tvalidation_0-auc:0.99020\n",
      "[46]\tvalidation_0-auc:0.99042\n",
      "[47]\tvalidation_0-auc:0.99071\n",
      "[48]\tvalidation_0-auc:0.99071\n",
      "[49]\tvalidation_0-auc:0.99102\n",
      "[50]\tvalidation_0-auc:0.99136\n",
      "[51]\tvalidation_0-auc:0.99151\n",
      "[52]\tvalidation_0-auc:0.99149\n",
      "[53]\tvalidation_0-auc:0.99133\n",
      "[54]\tvalidation_0-auc:0.99153\n",
      "[55]\tvalidation_0-auc:0.99180\n",
      "[56]\tvalidation_0-auc:0.99191\n",
      "[57]\tvalidation_0-auc:0.99196\n",
      "[58]\tvalidation_0-auc:0.99203\n",
      "[59]\tvalidation_0-auc:0.99213\n",
      "[60]\tvalidation_0-auc:0.99239\n",
      "[61]\tvalidation_0-auc:0.99223\n",
      "[62]\tvalidation_0-auc:0.99240\n",
      "[63]\tvalidation_0-auc:0.99257\n",
      "[64]\tvalidation_0-auc:0.99248\n",
      "[65]\tvalidation_0-auc:0.99246\n",
      "[66]\tvalidation_0-auc:0.99233\n",
      "[67]\tvalidation_0-auc:0.99249\n",
      "[68]\tvalidation_0-auc:0.99255\n",
      "[69]\tvalidation_0-auc:0.99279\n",
      "[70]\tvalidation_0-auc:0.99277\n",
      "[71]\tvalidation_0-auc:0.99265\n",
      "[72]\tvalidation_0-auc:0.99262\n",
      "[73]\tvalidation_0-auc:0.99290\n",
      "[74]\tvalidation_0-auc:0.99313\n",
      "[75]\tvalidation_0-auc:0.99314\n",
      "[76]\tvalidation_0-auc:0.99335\n",
      "[77]\tvalidation_0-auc:0.99337\n",
      "[78]\tvalidation_0-auc:0.99344\n",
      "[79]\tvalidation_0-auc:0.99351\n",
      "[80]\tvalidation_0-auc:0.99353\n",
      "[81]\tvalidation_0-auc:0.99344\n",
      "[82]\tvalidation_0-auc:0.99348\n",
      "[83]\tvalidation_0-auc:0.99349\n",
      "[84]\tvalidation_0-auc:0.99357\n",
      "[85]\tvalidation_0-auc:0.99354\n",
      "[86]\tvalidation_0-auc:0.99357\n",
      "[87]\tvalidation_0-auc:0.99352\n",
      "[88]\tvalidation_0-auc:0.99360\n",
      "[89]\tvalidation_0-auc:0.99378\n",
      "[90]\tvalidation_0-auc:0.99372\n",
      "[91]\tvalidation_0-auc:0.99377\n",
      "[92]\tvalidation_0-auc:0.99370\n",
      "[93]\tvalidation_0-auc:0.99366\n",
      "[94]\tvalidation_0-auc:0.99381\n",
      "[95]\tvalidation_0-auc:0.99382\n",
      "[96]\tvalidation_0-auc:0.99379\n",
      "[97]\tvalidation_0-auc:0.99388\n",
      "[98]\tvalidation_0-auc:0.99386\n",
      "[99]\tvalidation_0-auc:0.99375\n",
      "[100]\tvalidation_0-auc:0.99378\n",
      "[101]\tvalidation_0-auc:0.99397\n",
      "[102]\tvalidation_0-auc:0.99393\n",
      "[103]\tvalidation_0-auc:0.99399\n",
      "[104]\tvalidation_0-auc:0.99420\n",
      "[105]\tvalidation_0-auc:0.99422\n",
      "[106]\tvalidation_0-auc:0.99426\n",
      "[107]\tvalidation_0-auc:0.99422\n",
      "[108]\tvalidation_0-auc:0.99424\n",
      "[109]\tvalidation_0-auc:0.99431\n",
      "[110]\tvalidation_0-auc:0.99434\n",
      "[111]\tvalidation_0-auc:0.99420\n",
      "[112]\tvalidation_0-auc:0.99418\n",
      "[113]\tvalidation_0-auc:0.99426\n",
      "[114]\tvalidation_0-auc:0.99427\n",
      "[115]\tvalidation_0-auc:0.99423\n",
      "[116]\tvalidation_0-auc:0.99435\n",
      "[117]\tvalidation_0-auc:0.99430\n",
      "[118]\tvalidation_0-auc:0.99434\n",
      "[119]\tvalidation_0-auc:0.99435\n",
      "[120]\tvalidation_0-auc:0.99434\n",
      "[121]\tvalidation_0-auc:0.99447\n",
      "[122]\tvalidation_0-auc:0.99455\n",
      "[123]\tvalidation_0-auc:0.99457\n",
      "[124]\tvalidation_0-auc:0.99456\n",
      "[125]\tvalidation_0-auc:0.99459\n",
      "[126]\tvalidation_0-auc:0.99449\n",
      "[127]\tvalidation_0-auc:0.99457\n",
      "[128]\tvalidation_0-auc:0.99461\n",
      "[129]\tvalidation_0-auc:0.99450\n",
      "[130]\tvalidation_0-auc:0.99451\n",
      "[131]\tvalidation_0-auc:0.99445\n",
      "[132]\tvalidation_0-auc:0.99443\n",
      "[133]\tvalidation_0-auc:0.99447\n",
      "[134]\tvalidation_0-auc:0.99451\n",
      "[135]\tvalidation_0-auc:0.99456\n",
      "[136]\tvalidation_0-auc:0.99455\n",
      "[137]\tvalidation_0-auc:0.99446\n",
      "[138]\tvalidation_0-auc:0.99448\n",
      "[139]\tvalidation_0-auc:0.99445\n",
      "[140]\tvalidation_0-auc:0.99443\n",
      "[141]\tvalidation_0-auc:0.99452\n",
      "[142]\tvalidation_0-auc:0.99462\n",
      "[143]\tvalidation_0-auc:0.99463\n",
      "[144]\tvalidation_0-auc:0.99456\n",
      "[145]\tvalidation_0-auc:0.99452\n",
      "[146]\tvalidation_0-auc:0.99450\n",
      "[147]\tvalidation_0-auc:0.99448\n",
      "[148]\tvalidation_0-auc:0.99444\n",
      "[149]\tvalidation_0-auc:0.99436\n",
      "[150]\tvalidation_0-auc:0.99442\n",
      "[151]\tvalidation_0-auc:0.99449\n",
      "[152]\tvalidation_0-auc:0.99448\n",
      "[153]\tvalidation_0-auc:0.99443\n",
      "[154]\tvalidation_0-auc:0.99442\n",
      "[155]\tvalidation_0-auc:0.99438\n",
      "[156]\tvalidation_0-auc:0.99442\n",
      "[157]\tvalidation_0-auc:0.99447\n",
      "[158]\tvalidation_0-auc:0.99446\n",
      "[159]\tvalidation_0-auc:0.99450\n",
      "[160]\tvalidation_0-auc:0.99452\n",
      "[161]\tvalidation_0-auc:0.99451\n",
      "[162]\tvalidation_0-auc:0.99464\n",
      "[163]\tvalidation_0-auc:0.99461\n",
      "[164]\tvalidation_0-auc:0.99467\n",
      "[165]\tvalidation_0-auc:0.99463\n",
      "[166]\tvalidation_0-auc:0.99453\n",
      "[167]\tvalidation_0-auc:0.99453\n",
      "[168]\tvalidation_0-auc:0.99450\n",
      "[169]\tvalidation_0-auc:0.99455\n",
      "[170]\tvalidation_0-auc:0.99454\n",
      "[171]\tvalidation_0-auc:0.99448\n",
      "[172]\tvalidation_0-auc:0.99450\n",
      "[173]\tvalidation_0-auc:0.99450\n",
      "[174]\tvalidation_0-auc:0.99456\n",
      "[175]\tvalidation_0-auc:0.99457\n",
      "[176]\tvalidation_0-auc:0.99452\n",
      "[177]\tvalidation_0-auc:0.99447\n",
      "[178]\tvalidation_0-auc:0.99451\n",
      "[179]\tvalidation_0-auc:0.99456\n",
      "[180]\tvalidation_0-auc:0.99457\n",
      "[181]\tvalidation_0-auc:0.99462\n",
      "[182]\tvalidation_0-auc:0.99465\n",
      "[183]\tvalidation_0-auc:0.99469\n",
      "[184]\tvalidation_0-auc:0.99473\n",
      "[185]\tvalidation_0-auc:0.99476\n",
      "[186]\tvalidation_0-auc:0.99467\n",
      "[187]\tvalidation_0-auc:0.99472\n",
      "[188]\tvalidation_0-auc:0.99476\n",
      "[189]\tvalidation_0-auc:0.99470\n",
      "[190]\tvalidation_0-auc:0.99476\n",
      "[191]\tvalidation_0-auc:0.99484\n",
      "[192]\tvalidation_0-auc:0.99479\n",
      "[193]\tvalidation_0-auc:0.99482\n",
      "[194]\tvalidation_0-auc:0.99480\n",
      "[195]\tvalidation_0-auc:0.99488\n",
      "[196]\tvalidation_0-auc:0.99487\n",
      "[197]\tvalidation_0-auc:0.99492\n",
      "[198]\tvalidation_0-auc:0.99491\n",
      "[199]\tvalidation_0-auc:0.99491\n",
      "[200]\tvalidation_0-auc:0.99492\n",
      "[201]\tvalidation_0-auc:0.99486\n",
      "[202]\tvalidation_0-auc:0.99502\n",
      "[203]\tvalidation_0-auc:0.99502\n",
      "[204]\tvalidation_0-auc:0.99504\n",
      "[205]\tvalidation_0-auc:0.99505\n",
      "[206]\tvalidation_0-auc:0.99510\n",
      "[207]\tvalidation_0-auc:0.99507\n",
      "[208]\tvalidation_0-auc:0.99507\n",
      "[209]\tvalidation_0-auc:0.99504\n",
      "[210]\tvalidation_0-auc:0.99508\n",
      "[211]\tvalidation_0-auc:0.99502\n",
      "[212]\tvalidation_0-auc:0.99509\n",
      "[213]\tvalidation_0-auc:0.99512\n",
      "[214]\tvalidation_0-auc:0.99514\n",
      "[215]\tvalidation_0-auc:0.99524\n",
      "[216]\tvalidation_0-auc:0.99524\n",
      "[217]\tvalidation_0-auc:0.99521\n",
      "[218]\tvalidation_0-auc:0.99524\n",
      "[219]\tvalidation_0-auc:0.99526\n",
      "[220]\tvalidation_0-auc:0.99520\n",
      "[221]\tvalidation_0-auc:0.99523\n",
      "[222]\tvalidation_0-auc:0.99525\n",
      "[223]\tvalidation_0-auc:0.99523\n",
      "[224]\tvalidation_0-auc:0.99522\n",
      "[225]\tvalidation_0-auc:0.99525\n",
      "[226]\tvalidation_0-auc:0.99524\n",
      "[227]\tvalidation_0-auc:0.99516\n",
      "[228]\tvalidation_0-auc:0.99515\n",
      "[229]\tvalidation_0-auc:0.99524\n",
      "[230]\tvalidation_0-auc:0.99524\n",
      "[231]\tvalidation_0-auc:0.99527\n",
      "[232]\tvalidation_0-auc:0.99528\n",
      "[233]\tvalidation_0-auc:0.99525\n",
      "[234]\tvalidation_0-auc:0.99528\n",
      "[235]\tvalidation_0-auc:0.99525\n",
      "[236]\tvalidation_0-auc:0.99529\n",
      "[237]\tvalidation_0-auc:0.99526\n",
      "[238]\tvalidation_0-auc:0.99533\n",
      "[239]\tvalidation_0-auc:0.99530\n",
      "[240]\tvalidation_0-auc:0.99530\n",
      "[241]\tvalidation_0-auc:0.99534\n",
      "[242]\tvalidation_0-auc:0.99536\n",
      "[243]\tvalidation_0-auc:0.99536\n",
      "[244]\tvalidation_0-auc:0.99539\n",
      "[245]\tvalidation_0-auc:0.99542\n",
      "[246]\tvalidation_0-auc:0.99544\n",
      "[247]\tvalidation_0-auc:0.99539\n",
      "[248]\tvalidation_0-auc:0.99538\n",
      "[249]\tvalidation_0-auc:0.99534\n",
      "[250]\tvalidation_0-auc:0.99537\n",
      "[251]\tvalidation_0-auc:0.99537\n",
      "[252]\tvalidation_0-auc:0.99538\n",
      "[253]\tvalidation_0-auc:0.99544\n",
      "[254]\tvalidation_0-auc:0.99547\n",
      "[255]\tvalidation_0-auc:0.99549\n",
      "[256]\tvalidation_0-auc:0.99549\n",
      "[257]\tvalidation_0-auc:0.99550\n",
      "[258]\tvalidation_0-auc:0.99546\n",
      "[259]\tvalidation_0-auc:0.99542\n",
      "[260]\tvalidation_0-auc:0.99541\n",
      "[261]\tvalidation_0-auc:0.99538\n",
      "[262]\tvalidation_0-auc:0.99536\n",
      "[263]\tvalidation_0-auc:0.99542\n",
      "[264]\tvalidation_0-auc:0.99541\n",
      "[265]\tvalidation_0-auc:0.99538\n",
      "[266]\tvalidation_0-auc:0.99535\n",
      "[267]\tvalidation_0-auc:0.99536\n",
      "[268]\tvalidation_0-auc:0.99544\n",
      "[269]\tvalidation_0-auc:0.99545\n",
      "[270]\tvalidation_0-auc:0.99545\n",
      "[271]\tvalidation_0-auc:0.99547\n",
      "[272]\tvalidation_0-auc:0.99551\n",
      "[273]\tvalidation_0-auc:0.99549\n",
      "[274]\tvalidation_0-auc:0.99549\n",
      "[275]\tvalidation_0-auc:0.99547\n",
      "[276]\tvalidation_0-auc:0.99544\n",
      "[277]\tvalidation_0-auc:0.99547\n",
      "[278]\tvalidation_0-auc:0.99554\n",
      "[279]\tvalidation_0-auc:0.99553\n",
      "[280]\tvalidation_0-auc:0.99551\n",
      "[281]\tvalidation_0-auc:0.99549\n",
      "[282]\tvalidation_0-auc:0.99551\n",
      "[283]\tvalidation_0-auc:0.99549\n",
      "[284]\tvalidation_0-auc:0.99556\n",
      "[285]\tvalidation_0-auc:0.99549\n",
      "[286]\tvalidation_0-auc:0.99543\n",
      "[287]\tvalidation_0-auc:0.99549\n",
      "[288]\tvalidation_0-auc:0.99551\n",
      "[289]\tvalidation_0-auc:0.99554\n",
      "[290]\tvalidation_0-auc:0.99550\n",
      "[291]\tvalidation_0-auc:0.99550\n",
      "[292]\tvalidation_0-auc:0.99554\n",
      "[293]\tvalidation_0-auc:0.99552\n",
      "[294]\tvalidation_0-auc:0.99547\n",
      "[295]\tvalidation_0-auc:0.99552\n",
      "[296]\tvalidation_0-auc:0.99548\n",
      "[297]\tvalidation_0-auc:0.99550\n",
      "[298]\tvalidation_0-auc:0.99552\n",
      "[299]\tvalidation_0-auc:0.99555\n",
      "[300]\tvalidation_0-auc:0.99555\n",
      "[301]\tvalidation_0-auc:0.99554\n",
      "[302]\tvalidation_0-auc:0.99553\n",
      "[303]\tvalidation_0-auc:0.99557\n",
      "[304]\tvalidation_0-auc:0.99561\n",
      "[305]\tvalidation_0-auc:0.99564\n",
      "[306]\tvalidation_0-auc:0.99562\n",
      "[307]\tvalidation_0-auc:0.99562\n",
      "[308]\tvalidation_0-auc:0.99567\n",
      "[309]\tvalidation_0-auc:0.99569\n",
      "[310]\tvalidation_0-auc:0.99567\n",
      "[311]\tvalidation_0-auc:0.99571\n",
      "[312]\tvalidation_0-auc:0.99573\n",
      "[313]\tvalidation_0-auc:0.99572\n",
      "[314]\tvalidation_0-auc:0.99567\n",
      "[315]\tvalidation_0-auc:0.99564\n",
      "[316]\tvalidation_0-auc:0.99562\n",
      "[317]\tvalidation_0-auc:0.99560\n",
      "[318]\tvalidation_0-auc:0.99554\n",
      "[319]\tvalidation_0-auc:0.99552\n",
      "[320]\tvalidation_0-auc:0.99551\n",
      "[321]\tvalidation_0-auc:0.99554\n",
      "[322]\tvalidation_0-auc:0.99555\n",
      "[323]\tvalidation_0-auc:0.99558\n",
      "[324]\tvalidation_0-auc:0.99562\n",
      "[325]\tvalidation_0-auc:0.99562\n",
      "[326]\tvalidation_0-auc:0.99563\n",
      "[327]\tvalidation_0-auc:0.99564\n",
      "[328]\tvalidation_0-auc:0.99570\n",
      "[329]\tvalidation_0-auc:0.99569\n",
      "[330]\tvalidation_0-auc:0.99572\n",
      "[331]\tvalidation_0-auc:0.99573\n",
      "[332]\tvalidation_0-auc:0.99577\n",
      "[333]\tvalidation_0-auc:0.99581\n",
      "[334]\tvalidation_0-auc:0.99584\n",
      "[335]\tvalidation_0-auc:0.99587\n",
      "[336]\tvalidation_0-auc:0.99589\n",
      "[337]\tvalidation_0-auc:0.99587\n",
      "[338]\tvalidation_0-auc:0.99588\n",
      "[339]\tvalidation_0-auc:0.99588\n",
      "[340]\tvalidation_0-auc:0.99587\n",
      "[341]\tvalidation_0-auc:0.99587\n",
      "[342]\tvalidation_0-auc:0.99583\n",
      "[343]\tvalidation_0-auc:0.99589\n",
      "[344]\tvalidation_0-auc:0.99586\n",
      "[345]\tvalidation_0-auc:0.99587\n",
      "[346]\tvalidation_0-auc:0.99587\n",
      "[347]\tvalidation_0-auc:0.99588\n",
      "[348]\tvalidation_0-auc:0.99592\n",
      "[349]\tvalidation_0-auc:0.99592\n",
      "[350]\tvalidation_0-auc:0.99590\n",
      "[351]\tvalidation_0-auc:0.99590\n",
      "[352]\tvalidation_0-auc:0.99590\n",
      "[353]\tvalidation_0-auc:0.99588\n",
      "[354]\tvalidation_0-auc:0.99589\n",
      "[355]\tvalidation_0-auc:0.99590\n",
      "[356]\tvalidation_0-auc:0.99583\n",
      "[357]\tvalidation_0-auc:0.99582\n",
      "[358]\tvalidation_0-auc:0.99579\n",
      "[359]\tvalidation_0-auc:0.99582\n",
      "[360]\tvalidation_0-auc:0.99581\n",
      "[361]\tvalidation_0-auc:0.99579\n",
      "[362]\tvalidation_0-auc:0.99578\n",
      "[363]\tvalidation_0-auc:0.99579\n",
      "[364]\tvalidation_0-auc:0.99582\n",
      "[365]\tvalidation_0-auc:0.99588\n",
      "[366]\tvalidation_0-auc:0.99588\n",
      "[367]\tvalidation_0-auc:0.99593\n",
      "[368]\tvalidation_0-auc:0.99596\n",
      "[369]\tvalidation_0-auc:0.99592\n",
      "[370]\tvalidation_0-auc:0.99591\n",
      "[371]\tvalidation_0-auc:0.99594\n",
      "[372]\tvalidation_0-auc:0.99595\n",
      "[373]\tvalidation_0-auc:0.99596\n",
      "[374]\tvalidation_0-auc:0.99596\n",
      "[375]\tvalidation_0-auc:0.99600\n",
      "[376]\tvalidation_0-auc:0.99602\n",
      "[377]\tvalidation_0-auc:0.99603\n",
      "[378]\tvalidation_0-auc:0.99602\n",
      "[379]\tvalidation_0-auc:0.99606\n",
      "[380]\tvalidation_0-auc:0.99606\n",
      "[381]\tvalidation_0-auc:0.99608\n",
      "[382]\tvalidation_0-auc:0.99604\n",
      "[383]\tvalidation_0-auc:0.99607\n",
      "[384]\tvalidation_0-auc:0.99610\n",
      "[385]\tvalidation_0-auc:0.99609\n",
      "[386]\tvalidation_0-auc:0.99618\n",
      "[387]\tvalidation_0-auc:0.99619\n",
      "[388]\tvalidation_0-auc:0.99621\n",
      "[389]\tvalidation_0-auc:0.99621\n",
      "[390]\tvalidation_0-auc:0.99615\n",
      "[391]\tvalidation_0-auc:0.99612\n",
      "[392]\tvalidation_0-auc:0.99613\n",
      "[393]\tvalidation_0-auc:0.99617\n",
      "[394]\tvalidation_0-auc:0.99616\n",
      "[395]\tvalidation_0-auc:0.99620\n",
      "[396]\tvalidation_0-auc:0.99619\n",
      "[397]\tvalidation_0-auc:0.99621\n",
      "[398]\tvalidation_0-auc:0.99621\n",
      "[399]\tvalidation_0-auc:0.99621\n",
      "[400]\tvalidation_0-auc:0.99625\n",
      "[401]\tvalidation_0-auc:0.99626\n",
      "[402]\tvalidation_0-auc:0.99624\n",
      "[403]\tvalidation_0-auc:0.99626\n",
      "[404]\tvalidation_0-auc:0.99628\n",
      "[405]\tvalidation_0-auc:0.99625\n",
      "[406]\tvalidation_0-auc:0.99630\n",
      "[407]\tvalidation_0-auc:0.99631\n",
      "[408]\tvalidation_0-auc:0.99630\n",
      "[409]\tvalidation_0-auc:0.99632\n",
      "[410]\tvalidation_0-auc:0.99631\n",
      "[411]\tvalidation_0-auc:0.99630\n",
      "[412]\tvalidation_0-auc:0.99625\n",
      "[413]\tvalidation_0-auc:0.99627\n",
      "[414]\tvalidation_0-auc:0.99627\n",
      "[415]\tvalidation_0-auc:0.99629\n",
      "[416]\tvalidation_0-auc:0.99633\n",
      "[417]\tvalidation_0-auc:0.99636\n",
      "[418]\tvalidation_0-auc:0.99637\n",
      "[419]\tvalidation_0-auc:0.99639\n",
      "[420]\tvalidation_0-auc:0.99641\n",
      "[421]\tvalidation_0-auc:0.99640\n",
      "[422]\tvalidation_0-auc:0.99641\n",
      "[423]\tvalidation_0-auc:0.99641\n",
      "[424]\tvalidation_0-auc:0.99640\n",
      "[425]\tvalidation_0-auc:0.99647\n",
      "[426]\tvalidation_0-auc:0.99648\n",
      "[427]\tvalidation_0-auc:0.99648\n",
      "[428]\tvalidation_0-auc:0.99648\n",
      "[429]\tvalidation_0-auc:0.99649\n",
      "[430]\tvalidation_0-auc:0.99650\n",
      "[431]\tvalidation_0-auc:0.99650\n",
      "[432]\tvalidation_0-auc:0.99647\n",
      "[433]\tvalidation_0-auc:0.99645\n",
      "[434]\tvalidation_0-auc:0.99647\n",
      "[435]\tvalidation_0-auc:0.99649\n",
      "[436]\tvalidation_0-auc:0.99645\n",
      "[437]\tvalidation_0-auc:0.99646\n",
      "[438]\tvalidation_0-auc:0.99646\n",
      "[439]\tvalidation_0-auc:0.99643\n",
      "[440]\tvalidation_0-auc:0.99644\n",
      "[441]\tvalidation_0-auc:0.99643\n",
      "[442]\tvalidation_0-auc:0.99643\n",
      "[443]\tvalidation_0-auc:0.99644\n",
      "[444]\tvalidation_0-auc:0.99645\n",
      "[445]\tvalidation_0-auc:0.99649\n",
      "[446]\tvalidation_0-auc:0.99649\n",
      "[447]\tvalidation_0-auc:0.99651\n",
      "[448]\tvalidation_0-auc:0.99653\n",
      "[449]\tvalidation_0-auc:0.99655\n",
      "[450]\tvalidation_0-auc:0.99655\n",
      "[451]\tvalidation_0-auc:0.99655\n",
      "[452]\tvalidation_0-auc:0.99655\n",
      "[453]\tvalidation_0-auc:0.99656\n",
      "[454]\tvalidation_0-auc:0.99655\n",
      "[455]\tvalidation_0-auc:0.99655\n",
      "[456]\tvalidation_0-auc:0.99655\n",
      "[457]\tvalidation_0-auc:0.99655\n",
      "[458]\tvalidation_0-auc:0.99656\n",
      "[459]\tvalidation_0-auc:0.99658\n",
      "[460]\tvalidation_0-auc:0.99661\n",
      "[461]\tvalidation_0-auc:0.99659\n",
      "[462]\tvalidation_0-auc:0.99661\n",
      "[463]\tvalidation_0-auc:0.99659\n",
      "[464]\tvalidation_0-auc:0.99663\n",
      "[465]\tvalidation_0-auc:0.99661\n",
      "[466]\tvalidation_0-auc:0.99658\n",
      "[467]\tvalidation_0-auc:0.99660\n",
      "[468]\tvalidation_0-auc:0.99663\n",
      "[469]\tvalidation_0-auc:0.99664\n",
      "[470]\tvalidation_0-auc:0.99662\n",
      "[471]\tvalidation_0-auc:0.99661\n",
      "[472]\tvalidation_0-auc:0.99660\n",
      "[473]\tvalidation_0-auc:0.99656\n",
      "[474]\tvalidation_0-auc:0.99651\n",
      "[475]\tvalidation_0-auc:0.99655\n",
      "[476]\tvalidation_0-auc:0.99652\n",
      "[477]\tvalidation_0-auc:0.99653\n",
      "[478]\tvalidation_0-auc:0.99653\n",
      "[479]\tvalidation_0-auc:0.99652\n",
      "[480]\tvalidation_0-auc:0.99652\n",
      "[481]\tvalidation_0-auc:0.99654\n",
      "[482]\tvalidation_0-auc:0.99655\n",
      "[483]\tvalidation_0-auc:0.99657\n",
      "[484]\tvalidation_0-auc:0.99660\n",
      "[485]\tvalidation_0-auc:0.99663\n",
      "[486]\tvalidation_0-auc:0.99658\n",
      "[487]\tvalidation_0-auc:0.99655\n",
      "[488]\tvalidation_0-auc:0.99658\n",
      "[489]\tvalidation_0-auc:0.99652\n",
      "[490]\tvalidation_0-auc:0.99650\n",
      "[491]\tvalidation_0-auc:0.99650\n",
      "[492]\tvalidation_0-auc:0.99647\n",
      "[493]\tvalidation_0-auc:0.99644\n",
      "[494]\tvalidation_0-auc:0.99643\n",
      "[495]\tvalidation_0-auc:0.99644\n",
      "[496]\tvalidation_0-auc:0.99645\n",
      "[497]\tvalidation_0-auc:0.99645\n",
      "[498]\tvalidation_0-auc:0.99648\n",
      "[499]\tvalidation_0-auc:0.99649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      1660\n",
      "         1.0       1.00      0.91      0.95       166\n",
      "\n",
      "    accuracy                           0.99      1826\n",
      "   macro avg       1.00      0.95      0.97      1826\n",
      "weighted avg       0.99      0.99      0.99      1826\n",
      "\n",
      "AUC Score: 0.9965\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Define the XGBoost model\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',        # Use GPU acceleration\n",
    "    eval_metric='auc'   # Handle imbalance\n",
    ")\n",
    "\n",
    "# 7. Train the model\n",
    "model.fit(\n",
    "    X_param_train,\n",
    "    y_param_train,\n",
    "    eval_set=[(X_param_val, y_param_val)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 8. Predict and evaluate\n",
    "y_pred = model.predict(X_param_val)\n",
    "y_pred_proba = model.predict_proba(X_param_val)[:, 1]\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_param_val, y_pred))\n",
    "\n",
    "# AUC score\n",
    "auc = roc_auc_score(y_param_val, y_pred_proba)\n",
    "print(f\"AUC Score: {auc:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_param_val, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7a099",
   "metadata": {},
   "source": [
    "Initial results are pretty good for an untuned model: we've greatly reduced the False Positive Rate over the other models without losing any accuracy. Using the confusion matrix and AUC as my preferred evaluation metrics, let's try some tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc606c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      2\u001b[39m results = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lr \u001b[38;5;129;01min\u001b[39;00m learning_rates:\n\u001b[32m      5\u001b[39m     model = XGBClassifier(\n\u001b[32m      6\u001b[39m         n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m      7\u001b[39m         objective=\u001b[33m'\u001b[39m\u001b[33mbinary:logistic\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m         learning_rate=lr,\n\u001b[32m      9\u001b[39m         max_depth=\u001b[32m6\u001b[39m,\n\u001b[32m     10\u001b[39m         subsample=\u001b[32m0.8\u001b[39m,\n\u001b[32m     11\u001b[39m         colsample_bytree=\u001b[32m0.8\u001b[39m,\n\u001b[32m     12\u001b[39m         device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     13\u001b[39m         eval_metric=\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         scale_pos_weight=\u001b[43mpos_weight\u001b[49m\n\u001b[32m     15\u001b[39m     )\n\u001b[32m     17\u001b[39m     model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     18\u001b[39m     y_pred_proba = model.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'pos_weight' is not defined"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.03, 0.05, 0.1]\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=lr,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results.append((lr, auc))\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results], [x[1] for x in results], marker='o')\n",
    "plt.title('AUC Score vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(learning_rates)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0905ea",
   "metadata": {},
   "source": [
    "The various LR values don't seem to have a meaningful impact on the AUC score, dropping off slightly but then rebounding as we hit the end of the loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38b1e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "results_depth = []\n",
    "\n",
    "for depth in max_depths:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.03,\n",
    "        max_depth=depth,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_depth.append((depth, auc))\n",
    "    best_depth = depth if auc == max([x[1] for x in results_depth]) else best_depth\n",
    "\n",
    "\n",
    "best_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=best_depth,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=pos_weight\n",
    ")\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_depth], [x[1] for x in results_depth], marker='o')\n",
    "plt.title('AUC Score vs Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(max_depths)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6872951d",
   "metadata": {},
   "source": [
    "Max Depth is a little more interesting. Here the shallower models perform significantly better on the test set, suggesting that the model is overfitting when tree depth is increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcda8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_rates = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_subsample = []\n",
    "\n",
    "for rate in subsample_rates:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.03,\n",
    "        max_depth=best_depth,\n",
    "        subsample=rate,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_subsample.append((rate, auc))\n",
    "\n",
    "# print classification report for best subsample rate\n",
    "best_subsample_rate = max(results_subsample, key=lambda x: x[1])[0]\n",
    "best_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=best_depth,\n",
    "    subsample=best_subsample_rate,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=pos_weight\n",
    ")\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_subsample], [x[1] for x in results_subsample], marker='o')\n",
    "plt.title('AUC Score vs Subsample Rate')\n",
    "plt.xlabel('Subsample Rate')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(subsample_rates)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0afc4d",
   "metadata": {},
   "source": [
    "The subsample rate will adjust the Fraction of rows sampled per tree. Values < 1.0 add randomness and reduce overfitting. This is another Regularization technique to confol overfitting. Looks like .8 is the sweetspot here. \n",
    "\n",
    "Now let's put it all together with our best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=best_depth,\n",
    "    subsample=best_subsample_rate,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=pos_weight\n",
    ")\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc40cb",
   "metadata": {},
   "source": [
    "Next, onto our 2nd classification set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/pshmo/ai4l_final_project_2/ai4l_final_project/datasets/NFL-Punt-Analytics-Competition/processed_punt_data.csv')\n",
    "# Get boolean columns\n",
    "boolean_columns = df.select_dtypes(include='bool').columns\n",
    "\n",
    "# Convert boolean columns to integers (True -> 1, False -> 0)\n",
    "for col in boolean_columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Display the first few rows to verify the conversion\n",
    "print(\"Boolean columns converted to integers:\")\n",
    "print(df[boolean_columns].head())\n",
    "df = df.drop(columns=['season_year', 'gamekey', 'playid', 'gsisid'])\n",
    "\n",
    "# create X and y\n",
    "X = df.drop(columns=['injury'])\n",
    "y = df['injury']\n",
    "\n",
    "# Split into train / test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9f151",
   "metadata": {},
   "source": [
    "For fun, let's try our best parameters from the previous model and see what we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25af13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# compute class imbalance weight: \n",
    "pos_weight = (len(y) - sum(y)) / sum(y)\n",
    "\n",
    "# fit a basic xgboost classifier\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=pos_weight\n",
    ")\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be327454",
   "metadata": {},
   "source": [
    "Now we're getting somewhere: this is the best classification score I've ever pulled on this dataset. Let's try our tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd44cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 200, 300, 400, 500]\n",
    "results_n_estimators = []\n",
    "for n in n_estimators:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=n,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.03,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_n_estimators.append((n, auc))\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_n_estimators], [x[1] for x in results_n_estimators], marker='o')\n",
    "plt.title('AUC Score vs Number of Estimators')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(n_estimators)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [0.01, 0.03, 0.05, 0.1]\n",
    "results_lr = []\n",
    "for lr in learning_rates:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=lr,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_lr.append((lr, auc))\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_lr], [x[1] for x in results_lr], marker='o')\n",
    "plt.title('AUC Score vs Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(learning_rates)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325cb7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "results_max_depth = []\n",
    "for depth in max_depths:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.1,\n",
    "        max_depth=depth,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_max_depth.append((depth, auc))\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_max_depth], [x[1] for x in results_max_depth], marker='o')\n",
    "plt.title('AUC Score vs Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(max_depths)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbe742",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_rates = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_subsample = []\n",
    "for rate in subsample_rates:\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        objective='binary:logistic',\n",
    "        learning_rate=0.1,\n",
    "        max_depth=7,\n",
    "        subsample=rate,\n",
    "        colsample_bytree=0.8,\n",
    "        device='cuda',\n",
    "        eval_metric='auc',\n",
    "        scale_pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    results_subsample.append((rate, auc))\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([x[0] for x in results_subsample], [x[1] for x in results_subsample], marker='o')\n",
    "plt.title('AUC Score vs Subsample Rate')\n",
    "plt.xlabel('Subsample Rate')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.xticks(subsample_rates)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44737134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "best_model = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    objective='binary:logistic',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',\n",
    "    eval_metric='auc',\n",
    "    scale_pos_weight=pos_weight\n",
    ")\n",
    "best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "y_pred = best_model.predict(X_test)\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Best Model AUC: {roc_auc_score(y_test, best_model.predict_proba(X_test)[:, 1]):.4f}\")\n",
    "print(f\"Best Model Parameters: {best_model.get_params()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7def3",
   "metadata": {},
   "source": [
    "Not a lot of movement on the confusion matrix (we've managed to remove the one false positive). All in all we've got a pretty good set of evidence to suggest that gradient boosting is a strong candidate for model selection (I'm still working on getting the full time series represntation working)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372799b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c46db7cb",
   "metadata": {},
   "source": [
    "### Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80d2a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:7.53306\n",
      "[1]\tvalidation_0-rmse:7.41233\n",
      "[2]\tvalidation_0-rmse:7.23485\n",
      "[3]\tvalidation_0-rmse:7.12097\n",
      "[4]\tvalidation_0-rmse:7.02301\n",
      "[5]\tvalidation_0-rmse:6.86254\n",
      "[6]\tvalidation_0-rmse:6.70158\n",
      "[7]\tvalidation_0-rmse:6.54481\n",
      "[8]\tvalidation_0-rmse:6.39116\n",
      "[9]\tvalidation_0-rmse:6.30151\n",
      "[10]\tvalidation_0-rmse:6.16720\n",
      "[11]\tvalidation_0-rmse:6.03119\n",
      "[12]\tvalidation_0-rmse:5.90134\n",
      "[13]\tvalidation_0-rmse:5.77405\n",
      "[14]\tvalidation_0-rmse:5.66141\n",
      "[15]\tvalidation_0-rmse:5.54246\n",
      "[16]\tvalidation_0-rmse:5.47079\n",
      "[17]\tvalidation_0-rmse:5.35583\n",
      "[18]\tvalidation_0-rmse:5.24816\n",
      "[19]\tvalidation_0-rmse:5.15122\n",
      "[20]\tvalidation_0-rmse:5.05630\n",
      "[21]\tvalidation_0-rmse:4.96753\n",
      "[22]\tvalidation_0-rmse:4.91398\n",
      "[23]\tvalidation_0-rmse:4.82548\n",
      "[24]\tvalidation_0-rmse:4.74552\n",
      "[25]\tvalidation_0-rmse:4.66522\n",
      "[26]\tvalidation_0-rmse:4.58806\n",
      "[27]\tvalidation_0-rmse:4.50907\n",
      "[28]\tvalidation_0-rmse:4.47135\n",
      "[29]\tvalidation_0-rmse:4.40300\n",
      "[30]\tvalidation_0-rmse:4.32951\n",
      "[31]\tvalidation_0-rmse:4.26590\n",
      "[32]\tvalidation_0-rmse:4.20597\n",
      "[33]\tvalidation_0-rmse:4.15331\n",
      "[34]\tvalidation_0-rmse:4.09475\n",
      "[35]\tvalidation_0-rmse:4.04193\n",
      "[36]\tvalidation_0-rmse:3.99064\n",
      "[37]\tvalidation_0-rmse:3.94630\n",
      "[38]\tvalidation_0-rmse:3.91884\n",
      "[39]\tvalidation_0-rmse:3.87037\n",
      "[40]\tvalidation_0-rmse:3.82560\n",
      "[41]\tvalidation_0-rmse:3.78411\n",
      "[42]\tvalidation_0-rmse:3.74629\n",
      "[43]\tvalidation_0-rmse:3.70035\n",
      "[44]\tvalidation_0-rmse:3.68983\n",
      "[45]\tvalidation_0-rmse:3.66707\n",
      "[46]\tvalidation_0-rmse:3.63500\n",
      "[47]\tvalidation_0-rmse:3.59421\n",
      "[48]\tvalidation_0-rmse:3.56188\n",
      "[49]\tvalidation_0-rmse:3.53347\n",
      "[50]\tvalidation_0-rmse:3.51161\n",
      "[51]\tvalidation_0-rmse:3.48204\n",
      "[52]\tvalidation_0-rmse:3.44905\n",
      "[53]\tvalidation_0-rmse:3.42399\n",
      "[54]\tvalidation_0-rmse:3.40415\n",
      "[55]\tvalidation_0-rmse:3.38019\n",
      "[56]\tvalidation_0-rmse:3.35813\n",
      "[57]\tvalidation_0-rmse:3.32874\n",
      "[58]\tvalidation_0-rmse:3.30375\n",
      "[59]\tvalidation_0-rmse:3.29215\n",
      "[60]\tvalidation_0-rmse:3.26793\n",
      "[61]\tvalidation_0-rmse:3.25355\n",
      "[62]\tvalidation_0-rmse:3.23543\n",
      "[63]\tvalidation_0-rmse:3.21736\n",
      "[64]\tvalidation_0-rmse:3.20174\n",
      "[65]\tvalidation_0-rmse:3.18818\n",
      "[66]\tvalidation_0-rmse:3.17527\n",
      "[67]\tvalidation_0-rmse:3.16287\n",
      "[68]\tvalidation_0-rmse:3.15036\n",
      "[69]\tvalidation_0-rmse:3.13953\n",
      "[70]\tvalidation_0-rmse:3.12218\n",
      "[71]\tvalidation_0-rmse:3.10822\n",
      "[72]\tvalidation_0-rmse:3.10374\n",
      "[73]\tvalidation_0-rmse:3.09112\n",
      "[74]\tvalidation_0-rmse:3.08349\n",
      "[75]\tvalidation_0-rmse:3.07252\n",
      "[76]\tvalidation_0-rmse:3.06607\n",
      "[77]\tvalidation_0-rmse:3.05895\n",
      "[78]\tvalidation_0-rmse:3.04798\n",
      "[79]\tvalidation_0-rmse:3.03494\n",
      "[80]\tvalidation_0-rmse:3.03151\n",
      "[81]\tvalidation_0-rmse:3.02679\n",
      "[82]\tvalidation_0-rmse:3.01544\n",
      "[83]\tvalidation_0-rmse:3.00574\n",
      "[84]\tvalidation_0-rmse:2.99503\n",
      "[85]\tvalidation_0-rmse:2.98784\n",
      "[86]\tvalidation_0-rmse:2.98179\n",
      "[87]\tvalidation_0-rmse:2.97201\n",
      "[88]\tvalidation_0-rmse:2.96748\n",
      "[89]\tvalidation_0-rmse:2.95924\n",
      "[90]\tvalidation_0-rmse:2.94989\n",
      "[91]\tvalidation_0-rmse:2.94275\n",
      "[92]\tvalidation_0-rmse:2.93023\n",
      "[93]\tvalidation_0-rmse:2.92667\n",
      "[94]\tvalidation_0-rmse:2.92080\n",
      "[95]\tvalidation_0-rmse:2.91753\n",
      "[96]\tvalidation_0-rmse:2.91310\n",
      "[97]\tvalidation_0-rmse:2.90861\n",
      "[98]\tvalidation_0-rmse:2.90541\n",
      "[99]\tvalidation_0-rmse:2.89476\n",
      "[100]\tvalidation_0-rmse:2.88624\n",
      "[101]\tvalidation_0-rmse:2.88172\n",
      "[102]\tvalidation_0-rmse:2.87583\n",
      "[103]\tvalidation_0-rmse:2.87338\n",
      "[104]\tvalidation_0-rmse:2.86947\n",
      "[105]\tvalidation_0-rmse:2.86678\n",
      "[106]\tvalidation_0-rmse:2.85746\n",
      "[107]\tvalidation_0-rmse:2.85584\n",
      "[108]\tvalidation_0-rmse:2.85211\n",
      "[109]\tvalidation_0-rmse:2.84912\n",
      "[110]\tvalidation_0-rmse:2.84764\n",
      "[111]\tvalidation_0-rmse:2.84277\n",
      "[112]\tvalidation_0-rmse:2.84284\n",
      "[113]\tvalidation_0-rmse:2.84244\n",
      "[114]\tvalidation_0-rmse:2.83695\n",
      "[115]\tvalidation_0-rmse:2.83433\n",
      "[116]\tvalidation_0-rmse:2.83126\n",
      "[117]\tvalidation_0-rmse:2.82842\n",
      "[118]\tvalidation_0-rmse:2.82817\n",
      "[119]\tvalidation_0-rmse:2.82752\n",
      "[120]\tvalidation_0-rmse:2.82302\n",
      "[121]\tvalidation_0-rmse:2.82242\n",
      "[122]\tvalidation_0-rmse:2.82109\n",
      "[123]\tvalidation_0-rmse:2.81834\n",
      "[124]\tvalidation_0-rmse:2.81632\n",
      "[125]\tvalidation_0-rmse:2.81509\n",
      "[126]\tvalidation_0-rmse:2.81483\n",
      "[127]\tvalidation_0-rmse:2.81409\n",
      "[128]\tvalidation_0-rmse:2.81162\n",
      "[129]\tvalidation_0-rmse:2.80961\n",
      "[130]\tvalidation_0-rmse:2.80890\n",
      "[131]\tvalidation_0-rmse:2.80852\n",
      "[132]\tvalidation_0-rmse:2.80874\n",
      "[133]\tvalidation_0-rmse:2.80609\n",
      "[134]\tvalidation_0-rmse:2.80189\n",
      "[135]\tvalidation_0-rmse:2.79759\n",
      "[136]\tvalidation_0-rmse:2.79730\n",
      "[137]\tvalidation_0-rmse:2.79734\n",
      "[138]\tvalidation_0-rmse:2.79495\n",
      "[139]\tvalidation_0-rmse:2.79308\n",
      "[140]\tvalidation_0-rmse:2.79284\n",
      "[141]\tvalidation_0-rmse:2.79120\n",
      "[142]\tvalidation_0-rmse:2.79325\n",
      "[143]\tvalidation_0-rmse:2.79116\n",
      "[144]\tvalidation_0-rmse:2.79131\n",
      "[145]\tvalidation_0-rmse:2.78813\n",
      "[146]\tvalidation_0-rmse:2.78477\n",
      "[147]\tvalidation_0-rmse:2.78510\n",
      "[148]\tvalidation_0-rmse:2.78596\n",
      "[149]\tvalidation_0-rmse:2.78448\n",
      "[150]\tvalidation_0-rmse:2.78553\n",
      "[151]\tvalidation_0-rmse:2.78490\n",
      "[152]\tvalidation_0-rmse:2.78518\n",
      "[153]\tvalidation_0-rmse:2.78414\n",
      "[154]\tvalidation_0-rmse:2.78361\n",
      "[155]\tvalidation_0-rmse:2.78231\n",
      "[156]\tvalidation_0-rmse:2.77942\n",
      "[157]\tvalidation_0-rmse:2.77727\n",
      "[158]\tvalidation_0-rmse:2.77540\n",
      "[159]\tvalidation_0-rmse:2.77077\n",
      "[160]\tvalidation_0-rmse:2.76911\n",
      "[161]\tvalidation_0-rmse:2.76660\n",
      "[162]\tvalidation_0-rmse:2.76590\n",
      "[163]\tvalidation_0-rmse:2.76375\n",
      "[164]\tvalidation_0-rmse:2.76387\n",
      "[165]\tvalidation_0-rmse:2.76358\n",
      "[166]\tvalidation_0-rmse:2.76309\n",
      "[167]\tvalidation_0-rmse:2.76107\n",
      "[168]\tvalidation_0-rmse:2.76072\n",
      "[169]\tvalidation_0-rmse:2.75840\n",
      "[170]\tvalidation_0-rmse:2.75752\n",
      "[171]\tvalidation_0-rmse:2.75690\n",
      "[172]\tvalidation_0-rmse:2.75685\n",
      "[173]\tvalidation_0-rmse:2.75720\n",
      "[174]\tvalidation_0-rmse:2.75619\n",
      "[175]\tvalidation_0-rmse:2.75622\n",
      "[176]\tvalidation_0-rmse:2.75589\n",
      "[177]\tvalidation_0-rmse:2.75365\n",
      "[178]\tvalidation_0-rmse:2.75171\n",
      "[179]\tvalidation_0-rmse:2.75123\n",
      "[180]\tvalidation_0-rmse:2.75129\n",
      "[181]\tvalidation_0-rmse:2.75244\n",
      "[182]\tvalidation_0-rmse:2.75241\n",
      "[183]\tvalidation_0-rmse:2.75232\n",
      "[184]\tvalidation_0-rmse:2.75129\n",
      "[185]\tvalidation_0-rmse:2.75108\n",
      "[186]\tvalidation_0-rmse:2.75012\n",
      "[187]\tvalidation_0-rmse:2.75047\n",
      "[188]\tvalidation_0-rmse:2.75050\n",
      "[189]\tvalidation_0-rmse:2.74974\n",
      "[190]\tvalidation_0-rmse:2.74927\n",
      "[191]\tvalidation_0-rmse:2.75050\n",
      "[192]\tvalidation_0-rmse:2.75064\n",
      "[193]\tvalidation_0-rmse:2.75136\n",
      "[194]\tvalidation_0-rmse:2.75198\n",
      "[195]\tvalidation_0-rmse:2.75511\n",
      "[196]\tvalidation_0-rmse:2.75551\n",
      "[197]\tvalidation_0-rmse:2.75561\n",
      "[198]\tvalidation_0-rmse:2.75637\n",
      "[199]\tvalidation_0-rmse:2.75642\n",
      "[200]\tvalidation_0-rmse:2.75619\n",
      "[201]\tvalidation_0-rmse:2.75615\n",
      "[202]\tvalidation_0-rmse:2.75474\n",
      "[203]\tvalidation_0-rmse:2.75497\n",
      "[204]\tvalidation_0-rmse:2.75536\n",
      "[205]\tvalidation_0-rmse:2.75550\n",
      "[206]\tvalidation_0-rmse:2.75590\n",
      "[207]\tvalidation_0-rmse:2.75443\n",
      "[208]\tvalidation_0-rmse:2.75515\n",
      "[209]\tvalidation_0-rmse:2.75463\n",
      "[210]\tvalidation_0-rmse:2.75494\n",
      "[211]\tvalidation_0-rmse:2.75523\n",
      "[212]\tvalidation_0-rmse:2.75440\n",
      "[213]\tvalidation_0-rmse:2.75447\n",
      "[214]\tvalidation_0-rmse:2.75511\n",
      "[215]\tvalidation_0-rmse:2.75522\n",
      "[216]\tvalidation_0-rmse:2.75476\n",
      "[217]\tvalidation_0-rmse:2.75600\n",
      "[218]\tvalidation_0-rmse:2.75578\n",
      "[219]\tvalidation_0-rmse:2.75573\n",
      "[220]\tvalidation_0-rmse:2.75604\n",
      "[221]\tvalidation_0-rmse:2.75499\n",
      "[222]\tvalidation_0-rmse:2.75535\n",
      "[223]\tvalidation_0-rmse:2.75412\n",
      "[224]\tvalidation_0-rmse:2.75331\n",
      "[225]\tvalidation_0-rmse:2.75376\n",
      "[226]\tvalidation_0-rmse:2.75377\n",
      "[227]\tvalidation_0-rmse:2.75381\n",
      "[228]\tvalidation_0-rmse:2.75436\n",
      "[229]\tvalidation_0-rmse:2.75486\n",
      "[230]\tvalidation_0-rmse:2.75531\n",
      "[231]\tvalidation_0-rmse:2.75367\n",
      "[232]\tvalidation_0-rmse:2.75375\n",
      "[233]\tvalidation_0-rmse:2.75457\n",
      "[234]\tvalidation_0-rmse:2.75318\n",
      "[235]\tvalidation_0-rmse:2.75321\n",
      "[236]\tvalidation_0-rmse:2.75290\n",
      "[237]\tvalidation_0-rmse:2.75357\n",
      "[238]\tvalidation_0-rmse:2.75470\n",
      "[239]\tvalidation_0-rmse:2.75450\n",
      "[240]\tvalidation_0-rmse:2.75137\n",
      "[241]\tvalidation_0-rmse:2.75180\n",
      "[242]\tvalidation_0-rmse:2.75190\n",
      "[243]\tvalidation_0-rmse:2.75293\n",
      "[244]\tvalidation_0-rmse:2.75303\n",
      "[245]\tvalidation_0-rmse:2.75334\n",
      "[246]\tvalidation_0-rmse:2.75441\n",
      "[247]\tvalidation_0-rmse:2.75433\n",
      "[248]\tvalidation_0-rmse:2.75462\n",
      "[249]\tvalidation_0-rmse:2.75503\n",
      "[250]\tvalidation_0-rmse:2.75461\n",
      "[251]\tvalidation_0-rmse:2.75469\n",
      "[252]\tvalidation_0-rmse:2.75575\n",
      "[253]\tvalidation_0-rmse:2.75770\n",
      "[254]\tvalidation_0-rmse:2.75788\n",
      "[255]\tvalidation_0-rmse:2.75746\n",
      "[256]\tvalidation_0-rmse:2.75788\n",
      "[257]\tvalidation_0-rmse:2.75796\n",
      "[258]\tvalidation_0-rmse:2.75839\n",
      "[259]\tvalidation_0-rmse:2.75874\n",
      "[260]\tvalidation_0-rmse:2.75894\n",
      "[261]\tvalidation_0-rmse:2.75996\n",
      "[262]\tvalidation_0-rmse:2.76060\n",
      "[263]\tvalidation_0-rmse:2.76052\n",
      "[264]\tvalidation_0-rmse:2.76066\n",
      "[265]\tvalidation_0-rmse:2.76104\n",
      "[266]\tvalidation_0-rmse:2.76125\n",
      "[267]\tvalidation_0-rmse:2.76197\n",
      "[268]\tvalidation_0-rmse:2.76283\n",
      "[269]\tvalidation_0-rmse:2.76241\n",
      "[270]\tvalidation_0-rmse:2.76215\n",
      "[271]\tvalidation_0-rmse:2.76177\n",
      "[272]\tvalidation_0-rmse:2.76285\n",
      "[273]\tvalidation_0-rmse:2.76275\n",
      "[274]\tvalidation_0-rmse:2.76287\n",
      "[275]\tvalidation_0-rmse:2.76257\n",
      "[276]\tvalidation_0-rmse:2.76227\n",
      "[277]\tvalidation_0-rmse:2.76236\n",
      "[278]\tvalidation_0-rmse:2.76255\n",
      "[279]\tvalidation_0-rmse:2.76307\n",
      "[280]\tvalidation_0-rmse:2.76515\n",
      "[281]\tvalidation_0-rmse:2.76515\n",
      "[282]\tvalidation_0-rmse:2.76634\n",
      "[283]\tvalidation_0-rmse:2.76713\n",
      "[284]\tvalidation_0-rmse:2.76732\n",
      "[285]\tvalidation_0-rmse:2.76685\n",
      "[286]\tvalidation_0-rmse:2.76705\n",
      "[287]\tvalidation_0-rmse:2.76720\n",
      "[288]\tvalidation_0-rmse:2.76709\n",
      "[289]\tvalidation_0-rmse:2.76752\n",
      "[290]\tvalidation_0-rmse:2.76742\n",
      "[291]\tvalidation_0-rmse:2.76802\n",
      "[292]\tvalidation_0-rmse:2.76943\n",
      "[293]\tvalidation_0-rmse:2.76793\n",
      "[294]\tvalidation_0-rmse:2.76782\n",
      "[295]\tvalidation_0-rmse:2.76787\n",
      "[296]\tvalidation_0-rmse:2.76738\n",
      "[297]\tvalidation_0-rmse:2.76739\n",
      "[298]\tvalidation_0-rmse:2.76740\n",
      "[299]\tvalidation_0-rmse:2.76763\n",
      "[300]\tvalidation_0-rmse:2.76765\n",
      "[301]\tvalidation_0-rmse:2.76797\n",
      "[302]\tvalidation_0-rmse:2.76791\n",
      "[303]\tvalidation_0-rmse:2.76664\n",
      "[304]\tvalidation_0-rmse:2.76658\n",
      "[305]\tvalidation_0-rmse:2.76638\n",
      "[306]\tvalidation_0-rmse:2.76636\n",
      "[307]\tvalidation_0-rmse:2.76471\n",
      "[308]\tvalidation_0-rmse:2.76483\n",
      "[309]\tvalidation_0-rmse:2.76500\n",
      "[310]\tvalidation_0-rmse:2.76504\n",
      "[311]\tvalidation_0-rmse:2.76512\n",
      "[312]\tvalidation_0-rmse:2.76483\n",
      "[313]\tvalidation_0-rmse:2.76396\n",
      "[314]\tvalidation_0-rmse:2.76455\n",
      "[315]\tvalidation_0-rmse:2.76482\n",
      "[316]\tvalidation_0-rmse:2.76420\n",
      "[317]\tvalidation_0-rmse:2.76406\n",
      "[318]\tvalidation_0-rmse:2.76428\n",
      "[319]\tvalidation_0-rmse:2.76429\n",
      "[320]\tvalidation_0-rmse:2.76490\n",
      "[321]\tvalidation_0-rmse:2.76634\n",
      "[322]\tvalidation_0-rmse:2.76724\n",
      "[323]\tvalidation_0-rmse:2.76851\n",
      "[324]\tvalidation_0-rmse:2.76814\n",
      "[325]\tvalidation_0-rmse:2.76828\n",
      "[326]\tvalidation_0-rmse:2.76808\n",
      "[327]\tvalidation_0-rmse:2.76761\n",
      "[328]\tvalidation_0-rmse:2.76795\n",
      "[329]\tvalidation_0-rmse:2.76896\n",
      "[330]\tvalidation_0-rmse:2.76949\n",
      "[331]\tvalidation_0-rmse:2.76953\n",
      "[332]\tvalidation_0-rmse:2.77073\n",
      "[333]\tvalidation_0-rmse:2.77085\n",
      "[334]\tvalidation_0-rmse:2.77090\n",
      "[335]\tvalidation_0-rmse:2.77083\n",
      "[336]\tvalidation_0-rmse:2.77154\n",
      "[337]\tvalidation_0-rmse:2.77208\n",
      "[338]\tvalidation_0-rmse:2.77185\n",
      "[339]\tvalidation_0-rmse:2.77209\n",
      "[340]\tvalidation_0-rmse:2.77218\n",
      "[341]\tvalidation_0-rmse:2.77221\n",
      "[342]\tvalidation_0-rmse:2.77226\n",
      "[343]\tvalidation_0-rmse:2.77204\n",
      "[344]\tvalidation_0-rmse:2.77298\n",
      "[345]\tvalidation_0-rmse:2.77346\n",
      "[346]\tvalidation_0-rmse:2.77353\n",
      "[347]\tvalidation_0-rmse:2.77360\n",
      "[348]\tvalidation_0-rmse:2.77377\n",
      "[349]\tvalidation_0-rmse:2.77371\n",
      "[350]\tvalidation_0-rmse:2.77337\n",
      "[351]\tvalidation_0-rmse:2.77442\n",
      "[352]\tvalidation_0-rmse:2.77436\n",
      "[353]\tvalidation_0-rmse:2.77221\n",
      "[354]\tvalidation_0-rmse:2.77246\n",
      "[355]\tvalidation_0-rmse:2.77198\n",
      "[356]\tvalidation_0-rmse:2.77143\n",
      "[357]\tvalidation_0-rmse:2.77222\n",
      "[358]\tvalidation_0-rmse:2.77222\n",
      "[359]\tvalidation_0-rmse:2.77235\n",
      "[360]\tvalidation_0-rmse:2.77240\n",
      "[361]\tvalidation_0-rmse:2.77240\n",
      "[362]\tvalidation_0-rmse:2.77259\n",
      "[363]\tvalidation_0-rmse:2.77247\n",
      "[364]\tvalidation_0-rmse:2.77335\n",
      "[365]\tvalidation_0-rmse:2.77249\n",
      "[366]\tvalidation_0-rmse:2.77279\n",
      "[367]\tvalidation_0-rmse:2.77140\n",
      "[368]\tvalidation_0-rmse:2.77147\n",
      "[369]\tvalidation_0-rmse:2.77128\n",
      "[370]\tvalidation_0-rmse:2.77173\n",
      "[371]\tvalidation_0-rmse:2.77078\n",
      "[372]\tvalidation_0-rmse:2.77146\n",
      "[373]\tvalidation_0-rmse:2.77126\n",
      "[374]\tvalidation_0-rmse:2.77150\n",
      "[375]\tvalidation_0-rmse:2.77211\n",
      "[376]\tvalidation_0-rmse:2.77234\n",
      "[377]\tvalidation_0-rmse:2.77292\n",
      "[378]\tvalidation_0-rmse:2.77262\n",
      "[379]\tvalidation_0-rmse:2.77323\n",
      "[380]\tvalidation_0-rmse:2.77337\n",
      "[381]\tvalidation_0-rmse:2.77320\n",
      "[382]\tvalidation_0-rmse:2.77688\n",
      "[383]\tvalidation_0-rmse:2.77724\n",
      "[384]\tvalidation_0-rmse:2.77744\n",
      "[385]\tvalidation_0-rmse:2.77625\n",
      "[386]\tvalidation_0-rmse:2.77636\n",
      "[387]\tvalidation_0-rmse:2.77662\n",
      "[388]\tvalidation_0-rmse:2.77672\n",
      "[389]\tvalidation_0-rmse:2.77681\n",
      "[390]\tvalidation_0-rmse:2.77718\n",
      "[391]\tvalidation_0-rmse:2.77776\n",
      "[392]\tvalidation_0-rmse:2.77807\n",
      "[393]\tvalidation_0-rmse:2.77768\n",
      "[394]\tvalidation_0-rmse:2.77720\n",
      "[395]\tvalidation_0-rmse:2.77715\n",
      "[396]\tvalidation_0-rmse:2.77572\n",
      "[397]\tvalidation_0-rmse:2.77587\n",
      "[398]\tvalidation_0-rmse:2.77595\n",
      "[399]\tvalidation_0-rmse:2.77617\n",
      "[400]\tvalidation_0-rmse:2.77688\n",
      "[401]\tvalidation_0-rmse:2.77735\n",
      "[402]\tvalidation_0-rmse:2.77719\n",
      "[403]\tvalidation_0-rmse:2.77714\n",
      "[404]\tvalidation_0-rmse:2.77749\n",
      "[405]\tvalidation_0-rmse:2.77728\n",
      "[406]\tvalidation_0-rmse:2.77758\n",
      "[407]\tvalidation_0-rmse:2.77856\n",
      "[408]\tvalidation_0-rmse:2.77896\n",
      "[409]\tvalidation_0-rmse:2.77931\n",
      "[410]\tvalidation_0-rmse:2.77950\n",
      "[411]\tvalidation_0-rmse:2.77960\n",
      "[412]\tvalidation_0-rmse:2.77986\n",
      "[413]\tvalidation_0-rmse:2.77895\n",
      "[414]\tvalidation_0-rmse:2.77900\n",
      "[415]\tvalidation_0-rmse:2.77966\n",
      "[416]\tvalidation_0-rmse:2.77872\n",
      "[417]\tvalidation_0-rmse:2.77874\n",
      "[418]\tvalidation_0-rmse:2.77879\n",
      "[419]\tvalidation_0-rmse:2.77831\n",
      "[420]\tvalidation_0-rmse:2.77833\n",
      "[421]\tvalidation_0-rmse:2.77830\n",
      "[422]\tvalidation_0-rmse:2.77830\n",
      "[423]\tvalidation_0-rmse:2.77942\n",
      "[424]\tvalidation_0-rmse:2.77866\n",
      "[425]\tvalidation_0-rmse:2.77759\n",
      "[426]\tvalidation_0-rmse:2.77724\n",
      "[427]\tvalidation_0-rmse:2.77711\n",
      "[428]\tvalidation_0-rmse:2.77720\n",
      "[429]\tvalidation_0-rmse:2.77842\n",
      "[430]\tvalidation_0-rmse:2.77839\n",
      "[431]\tvalidation_0-rmse:2.77857\n",
      "[432]\tvalidation_0-rmse:2.77823\n",
      "[433]\tvalidation_0-rmse:2.77785\n",
      "[434]\tvalidation_0-rmse:2.77835\n",
      "[435]\tvalidation_0-rmse:2.77714\n",
      "[436]\tvalidation_0-rmse:2.77708\n",
      "[437]\tvalidation_0-rmse:2.77677\n",
      "[438]\tvalidation_0-rmse:2.77688\n",
      "[439]\tvalidation_0-rmse:2.77561\n",
      "[440]\tvalidation_0-rmse:2.77557\n",
      "[441]\tvalidation_0-rmse:2.77569\n",
      "[442]\tvalidation_0-rmse:2.77551\n",
      "[443]\tvalidation_0-rmse:2.77572\n",
      "[444]\tvalidation_0-rmse:2.77557\n",
      "[445]\tvalidation_0-rmse:2.77581\n",
      "[446]\tvalidation_0-rmse:2.77487\n",
      "[447]\tvalidation_0-rmse:2.77452\n",
      "[448]\tvalidation_0-rmse:2.77467\n",
      "[449]\tvalidation_0-rmse:2.77514\n",
      "[450]\tvalidation_0-rmse:2.77492\n",
      "[451]\tvalidation_0-rmse:2.77582\n",
      "[452]\tvalidation_0-rmse:2.77607\n",
      "[453]\tvalidation_0-rmse:2.77695\n",
      "[454]\tvalidation_0-rmse:2.77672\n",
      "[455]\tvalidation_0-rmse:2.77700\n",
      "[456]\tvalidation_0-rmse:2.77608\n",
      "[457]\tvalidation_0-rmse:2.77655\n",
      "[458]\tvalidation_0-rmse:2.77636\n",
      "[459]\tvalidation_0-rmse:2.77630\n",
      "[460]\tvalidation_0-rmse:2.77757\n",
      "[461]\tvalidation_0-rmse:2.77753\n",
      "[462]\tvalidation_0-rmse:2.77748\n",
      "[463]\tvalidation_0-rmse:2.77740\n",
      "[464]\tvalidation_0-rmse:2.77767\n",
      "[465]\tvalidation_0-rmse:2.77770\n",
      "[466]\tvalidation_0-rmse:2.77817\n",
      "[467]\tvalidation_0-rmse:2.77836\n",
      "[468]\tvalidation_0-rmse:2.77836\n",
      "[469]\tvalidation_0-rmse:2.77848\n",
      "[470]\tvalidation_0-rmse:2.77868\n",
      "[471]\tvalidation_0-rmse:2.77780\n",
      "[472]\tvalidation_0-rmse:2.77794\n",
      "[473]\tvalidation_0-rmse:2.77749\n",
      "[474]\tvalidation_0-rmse:2.77758\n",
      "[475]\tvalidation_0-rmse:2.77712\n",
      "[476]\tvalidation_0-rmse:2.77632\n",
      "[477]\tvalidation_0-rmse:2.77612\n",
      "[478]\tvalidation_0-rmse:2.77557\n",
      "[479]\tvalidation_0-rmse:2.77604\n",
      "[480]\tvalidation_0-rmse:2.77654\n",
      "[481]\tvalidation_0-rmse:2.77615\n",
      "[482]\tvalidation_0-rmse:2.77569\n",
      "[483]\tvalidation_0-rmse:2.77583\n",
      "[484]\tvalidation_0-rmse:2.77603\n",
      "[485]\tvalidation_0-rmse:2.77609\n",
      "[486]\tvalidation_0-rmse:2.77656\n",
      "[487]\tvalidation_0-rmse:2.77673\n",
      "[488]\tvalidation_0-rmse:2.77596\n",
      "[489]\tvalidation_0-rmse:2.77595\n",
      "[490]\tvalidation_0-rmse:2.77625\n",
      "[491]\tvalidation_0-rmse:2.77631\n",
      "[492]\tvalidation_0-rmse:2.77631\n",
      "[493]\tvalidation_0-rmse:2.77642\n",
      "[494]\tvalidation_0-rmse:2.77670\n",
      "[495]\tvalidation_0-rmse:2.77753\n",
      "[496]\tvalidation_0-rmse:2.77818\n",
      "[497]\tvalidation_0-rmse:2.77761\n",
      "[498]\tvalidation_0-rmse:2.77770\n",
      "[499]\tvalidation_0-rmse:2.77801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device=&#x27;cuda&#x27;, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=&#x27;rmse&#x27;, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=0.8, device='cuda', early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=0.03, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=500, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train = pd.read_csv('scripts/big_data_bowl/X_train.csv')\n",
    "y_train = pd.read_csv('scripts/big_data_bowl/y_train.csv')\n",
    "y_test = pd.read_csv('scripts/big_data_bowl/y_test.csv') \n",
    "X_test = pd.read_csv('scripts/big_data_bowl/X_test.csv')\n",
    "\n",
    "# Define the XGBoost regressor model\n",
    "model = XGBRegressor(\n",
    "    n_estimators=500,\n",
    "    objective='reg:squarederror',\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    device='cuda',  # Use GPU acceleration\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6c03fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R^2: 0.8707\n",
      "Feature Importances:\n",
      "                                 feature  importance\n",
      "99                  prePenaltyPlayResult    0.164065\n",
      "114                             pff_sack    0.132311\n",
      "67                          passResult_S    0.113584\n",
      "65                         passResult_IN    0.087588\n",
      "64                          passResult_I    0.054391\n",
      "102                       pff_playAction    0.032162\n",
      "76                 dropBackType_SCRAMBLE    0.022940\n",
      "74   dropBackType_DESIGNED_ROLLOUT_RIGHT    0.011354\n",
      "79              dropBackType_TRADITIONAL    0.010968\n",
      "118                      pff_sackAllowed    0.008587\n",
      "Predictions for the first 10 samples: [ 7.315037   11.958672   -0.06932306 -0.40156507 13.571005   23.90126\n",
      " 17.136322   19.158794    9.161526    0.43433   ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "model_r2 = model.score(X_test, y_test)\n",
    "print(f\"Model R^2: {model_r2:.4f}\")\n",
    "print(\"Feature Importances:\")\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "print(feature_importance_df.head(10))\n",
    "print(f\"Predictions for the first 10 samples: {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "112cf8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "feature",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "importance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "534925da-92cc-49eb-8896-4e0712148e7e",
       "rows": [
        [
         "99",
         "prePenaltyPlayResult",
         "0.16406535"
        ],
        [
         "114",
         "pff_sack",
         "0.1323106"
        ],
        [
         "67",
         "passResult_S",
         "0.11358358"
        ],
        [
         "65",
         "passResult_IN",
         "0.08758807"
        ],
        [
         "64",
         "passResult_I",
         "0.054390956"
        ],
        [
         "102",
         "pff_playAction",
         "0.03216181"
        ],
        [
         "76",
         "dropBackType_SCRAMBLE",
         "0.022940006"
        ],
        [
         "74",
         "dropBackType_DESIGNED_ROLLOUT_RIGHT",
         "0.011353954"
        ],
        [
         "79",
         "dropBackType_TRADITIONAL",
         "0.01096824"
        ],
        [
         "118",
         "pff_sackAllowed",
         "0.008587167"
        ],
        [
         "72",
         "offenseFormation_SINGLEBACK",
         "0.008087786"
        ],
        [
         "117",
         "pff_hurryAllowed",
         "0.007991712"
        ],
        [
         "101",
         "defendersInBox",
         "0.007827889"
        ],
        [
         "71",
         "offenseFormation_SHOTGUN",
         "0.007099581"
        ],
        [
         "91",
         "pff_passCoverage_Red Zone",
         "0.006859275"
        ],
        [
         "40",
         "defensiveTeam_DAL",
         "0.006378688"
        ],
        [
         "113",
         "pff_hurry",
         "0.006297465"
        ],
        [
         "66",
         "passResult_R",
         "0.005900944"
        ],
        [
         "63",
         "defensiveTeam_WAS",
         "0.005835846"
        ],
        [
         "60",
         "defensiveTeam_SF",
         "0.0057587693"
        ],
        [
         "92",
         "pff_passCoverageType_Other",
         "0.00566996"
        ],
        [
         "58",
         "defensiveTeam_PIT",
         "0.005506277"
        ],
        [
         "78",
         "dropBackType_SCRAMBLE_ROLLOUT_RIGHT",
         "0.005438246"
        ],
        [
         "27",
         "possessionTeam_PIT",
         "0.005291389"
        ],
        [
         "110",
         "DL_defensecount",
         "0.0052846908"
        ],
        [
         "32",
         "possessionTeam_WAS",
         "0.0050806333"
        ],
        [
         "103",
         "RB_offensecount",
         "0.0050732335"
        ],
        [
         "15",
         "possessionTeam_JAX",
         "0.004946054"
        ],
        [
         "119",
         "pff_backFieldBlock",
         "0.004940385"
        ],
        [
         "100",
         "absoluteYardlineNumber",
         "0.0047272374"
        ],
        [
         "115",
         "pff_beatenByDefender",
         "0.004680985"
        ],
        [
         "7",
         "possessionTeam_CIN",
         "0.0046622586"
        ],
        [
         "59",
         "defensiveTeam_SEA",
         "0.004306988"
        ],
        [
         "30",
         "possessionTeam_TB",
         "0.004244077"
        ],
        [
         "29",
         "possessionTeam_SF",
         "0.00397481"
        ],
        [
         "10",
         "possessionTeam_DEN",
         "0.003948411"
        ],
        [
         "39",
         "defensiveTeam_CLE",
         "0.0038599235"
        ],
        [
         "61",
         "defensiveTeam_TB",
         "0.003812942"
        ],
        [
         "4",
         "possessionTeam_BUF",
         "0.0038062844"
        ],
        [
         "48",
         "defensiveTeam_LA",
         "0.003722437"
        ],
        [
         "42",
         "defensiveTeam_DET",
         "0.0037130036"
        ],
        [
         "37",
         "defensiveTeam_CHI",
         "0.0036132564"
        ],
        [
         "2",
         "possessionTeam_ATL",
         "0.0035929556"
        ],
        [
         "20",
         "possessionTeam_MIA",
         "0.0035872064"
        ],
        [
         "43",
         "defensiveTeam_GB",
         "0.003526952"
        ],
        [
         "22",
         "possessionTeam_NE",
         "0.0034708763"
        ],
        [
         "35",
         "defensiveTeam_BUF",
         "0.0034458265"
        ],
        [
         "50",
         "defensiveTeam_LV",
         "0.0034307784"
        ],
        [
         "11",
         "possessionTeam_DET",
         "0.0034045258"
        ],
        [
         "98",
         "preSnapVisitorScore",
         "0.003401664"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 120
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>prePenaltyPlayResult</td>\n",
       "      <td>0.164065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>pff_sack</td>\n",
       "      <td>0.132311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>passResult_S</td>\n",
       "      <td>0.113584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>passResult_IN</td>\n",
       "      <td>0.087588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>passResult_I</td>\n",
       "      <td>0.054391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>pff_passCoverage_Prevent</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>QB_offensecount</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>offenseFormation_WILDCAT</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>pff_passCoverage_Miscellaneous</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>LB_offensecount</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            feature  importance\n",
       "99             prePenaltyPlayResult    0.164065\n",
       "114                        pff_sack    0.132311\n",
       "67                     passResult_S    0.113584\n",
       "65                    passResult_IN    0.087588\n",
       "64                     passResult_I    0.054391\n",
       "..                              ...         ...\n",
       "89         pff_passCoverage_Prevent    0.000436\n",
       "107                 QB_offensecount    0.000303\n",
       "73         offenseFormation_WILDCAT    0.000000\n",
       "88   pff_passCoverage_Miscellaneous    0.000000\n",
       "108                 LB_offensecount    0.000000\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ff96d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
