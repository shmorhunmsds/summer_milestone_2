{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "440b22dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/nl2zz_ln4d55dcscl_vvjglh0000gn/T/ipykernel_13637/3101525624.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 of 632 games\n",
      "Processed 20 of 632 games\n",
      "Processed 30 of 632 games\n",
      "Processed 40 of 632 games\n",
      "Processed 50 of 632 games\n",
      "Processed 60 of 632 games\n",
      "Processed 70 of 632 games\n",
      "Processed 80 of 632 games\n",
      "Processed 90 of 632 games\n",
      "Processed 100 of 632 games\n",
      "Processed 110 of 632 games\n",
      "Processed 120 of 632 games\n",
      "Processed 130 of 632 games\n",
      "Processed 140 of 632 games\n",
      "Processed 150 of 632 games\n",
      "Processed 160 of 632 games\n",
      "Processed 170 of 632 games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/nl2zz_ln4d55dcscl_vvjglh0000gn/T/ipykernel_13637/3101525624.py:48: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  chunk_df['time'] = pd.to_datetime(chunk_df['time'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 180 of 632 games\n",
      "Processed 190 of 632 games\n",
      "Processed 200 of 632 games\n",
      "Processed 210 of 632 games\n",
      "Processed 220 of 632 games\n",
      "Processed 230 of 632 games\n",
      "Processed 240 of 632 games\n",
      "Processed 250 of 632 games\n",
      "Processed 260 of 632 games\n",
      "Processed 270 of 632 games\n",
      "Processed 280 of 632 games\n",
      "Processed 290 of 632 games\n",
      "Processed 300 of 632 games\n",
      "Processed 310 of 632 games\n",
      "Processed 320 of 632 games\n",
      "Processed 330 of 632 games\n",
      "Processed 340 of 632 games\n",
      "Processed 350 of 632 games\n",
      "Processed 360 of 632 games\n",
      "Processed 370 of 632 games\n",
      "Processed 380 of 632 games\n",
      "Processed 390 of 632 games\n",
      "Processed 400 of 632 games\n",
      "Processed 410 of 632 games\n",
      "Processed 420 of 632 games\n",
      "Processed 430 of 632 games\n",
      "Processed 440 of 632 games\n",
      "Processed 450 of 632 games\n",
      "Processed 460 of 632 games\n",
      "Processed 470 of 632 games\n",
      "Processed 480 of 632 games\n",
      "Processed 490 of 632 games\n",
      "Processed 500 of 632 games\n",
      "Processed 510 of 632 games\n",
      "Processed 520 of 632 games\n",
      "Processed 530 of 632 games\n",
      "Processed 540 of 632 games\n",
      "Processed 550 of 632 games\n",
      "Processed 560 of 632 games\n",
      "Processed 570 of 632 games\n",
      "Processed 580 of 632 games\n",
      "Processed 590 of 632 games\n",
      "Processed 600 of 632 games\n",
      "Processed 610 of 632 games\n",
      "Processed 620 of 632 games\n",
      "Processed 630 of 632 games\n",
      "Processed 632 of 632 games\n",
      "274208 (274208, 40)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_normalize(path):\n",
    "    \"\"\"Load a CSV, strip and lowercase its column names.\"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "# NGS chunks for 2016 & 2017\n",
    "ngs_paths = [\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2016-pre.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2016-post.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2016-reg-wk1-6.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2016-reg-wk7-12.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2016-reg-wk13-17.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2017-pre.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2017-post.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2017-reg-wk1-6.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2017-reg-wk7-12.csv',\n",
    "    '/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/NGS-2017-reg-wk13-17.csv',\n",
    "]\n",
    "df = pd.concat([load_and_normalize(p) for p in ngs_paths], ignore_index=True)\n",
    "\n",
    "ndtypes = {'gamekey': 'int16',         \n",
    "           'playid': 'int16',         \n",
    "           'gsisid': 'float32',        \n",
    "           'time': 'str',         \n",
    "           'x': 'float32',         \n",
    "           'y': 'float32',         \n",
    "           'dis': 'float32',\n",
    "           'o': 'float32',\n",
    "           'event': 'str'}\n",
    "\n",
    "df = df.astype(ndtypes)\n",
    "df.dropna(subset='gsisid', inplace=True)\n",
    "#df['gsisid'] = df['gsisid'].fillna(-1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "def process_motion_chunk(chunk_df):\n",
    "    # Make an explicit copy to avoid warnings\n",
    "    chunk_df = chunk_df.copy()\n",
    "    \n",
    "    # Convert to datetime\n",
    "    chunk_df['time'] = pd.to_datetime(chunk_df['time'])\n",
    "    \n",
    "    # Calculate relative time from play start\n",
    "    chunk_df['relative_time'] = chunk_df.groupby(['season_year', 'gamekey', 'playid', 'gsisid'])['time'].transform(\n",
    "        lambda x: (x - x.min()).dt.total_seconds()\n",
    "    )\n",
    "    \n",
    "    # Create time deciles\n",
    "    chunk_df['time_decile'] = chunk_df.groupby(['season_year', 'gamekey', 'playid', 'gsisid'])['relative_time'].transform(\n",
    "        lambda x: pd.cut(x, bins=10, labels=[f'slice_{i}' for i in range(10)])\n",
    "    )\n",
    "    \n",
    "    # Pivot to wide\n",
    "    motion_wide = chunk_df.pivot_table(\n",
    "        index=['season_year', 'gamekey', 'playid', 'gsisid'], \n",
    "        columns='time_decile',\n",
    "        values=['dis', 'x', 'y', 'o'],\n",
    "        aggfunc='mean',\n",
    "        observed=True\n",
    "    )\n",
    "    \n",
    "    # Flatten columns\n",
    "    motion_wide.columns = [f'{metric}_{time}' for metric, time in motion_wide.columns]\n",
    "    \n",
    "    # Fill missing values by interpolating across time slices\n",
    "    for metric in ['dis', 'x', 'y', 'o']:\n",
    "        metric_cols = [f'{metric}_slice_{i}' for i in range(10)]\n",
    "        motion_wide[metric_cols] = motion_wide[metric_cols].interpolate(axis=1, method='linear')\n",
    "    \n",
    "    return motion_wide\n",
    "\n",
    "# Process in chunks\n",
    "motion_wide_list = []\n",
    "unique_games = df['gamekey'].unique()\n",
    "\n",
    "for i in range(0, len(unique_games), 10):  # Process 10 games at a time\n",
    "    game_chunk = unique_games[i:i+10]\n",
    "    chunk_df = df[df['gamekey'].isin(game_chunk)]\n",
    "    \n",
    "    motion_wide_chunk = process_motion_chunk(chunk_df)\n",
    "    motion_wide_list.append(motion_wide_chunk)\n",
    "    \n",
    "    print(f\"Processed {i+len(game_chunk)} of {len(unique_games)} games\")\n",
    "\n",
    "# Combine all chunks\n",
    "motion_wide = pd.concat(motion_wide_list, axis=0)\n",
    "\n",
    "print(len(motion_wide), motion_wide.shape)\n",
    "motion_wide.reset_index(inplace=True)\n",
    "revs = load_and_normalize('/Users/petershmorhun/Documents/GitHub/summer_milestone_2/datasets/NFL-Punt-Analytics-Competition/video_review.csv')\n",
    "df_final = motion_wide.merge(revs, on=['season_year', 'gamekey', 'playid', 'gsisid'], how='left')\n",
    "df_final['concussed'] = df_final['player_activity_derived'].notnull().astype(int)\n",
    "df_final.dropna(subset=['dis_slice_0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b03350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['season_year', 'gamekey', 'playid', 'gsisid', 'dis_slice_0',\n",
      "       'dis_slice_1', 'dis_slice_2', 'dis_slice_3', 'dis_slice_4',\n",
      "       'dis_slice_5', 'dis_slice_6', 'dis_slice_7', 'dis_slice_8',\n",
      "       'dis_slice_9', 'o_slice_0', 'o_slice_1', 'o_slice_2', 'o_slice_3',\n",
      "       'o_slice_4', 'o_slice_5', 'o_slice_6', 'o_slice_7', 'o_slice_8',\n",
      "       'o_slice_9', 'x_slice_0', 'x_slice_1', 'x_slice_2', 'x_slice_3',\n",
      "       'x_slice_4', 'x_slice_5', 'x_slice_6', 'x_slice_7', 'x_slice_8',\n",
      "       'x_slice_9', 'y_slice_0', 'y_slice_1', 'y_slice_2', 'y_slice_3',\n",
      "       'y_slice_4', 'y_slice_5', 'y_slice_6', 'y_slice_7', 'y_slice_8',\n",
      "       'y_slice_9', 'player_activity_derived', 'turnover_related',\n",
      "       'primary_impact_type', 'primary_partner_gsisid',\n",
      "       'primary_partner_activity_derived', 'friendly_fire', 'concussed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13f562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv)",
   "language": "python",
   "name": "uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
